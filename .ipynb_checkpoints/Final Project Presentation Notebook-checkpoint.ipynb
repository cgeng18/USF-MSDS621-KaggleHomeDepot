{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Project - Presentation Version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group Name: Lambda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Student Names\n",
    "1. Jian Wang\n",
    "2. Chong Geng\n",
    "3. Alan Perry\n",
    "4. Divya Bhargavi\n",
    "5. Robert Sandor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions & Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-07T01:09:45.985812Z",
     "start_time": "2018-12-07T01:09:44.144941Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/robertsandor/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict, Counter\n",
    "from Levenshtein import distance\n",
    "import lzma\n",
    "import math\n",
    "from math import sqrt\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.stem.porter import *\n",
    "import operator\n",
    "import os\n",
    "import re\n",
    "from scipy import spatial\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor, GradientBoostingRegressor\n",
    "from sklearn.feature_extraction import stop_words\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge, ElasticNet\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "import string\n",
    "import sys\n",
    "import time\n",
    "import xml.etree.cElementTree as ET\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-06T18:37:01.515122Z",
     "start_time": "2018-12-06T18:37:01.509994Z"
    }
   },
   "outputs": [],
   "source": [
    "def make_dictionary(file):\n",
    "    '''\n",
    "    Initiate the glove model as a dictionary\n",
    "    input: A String which is a file in the project directory\n",
    "    returns: A dictionary with item = word : 300 d list\n",
    "\n",
    "    :param file:            the filepath string of the dictionary\n",
    "    :returns:               a dictionary with words as keys \n",
    "                            and 300d vectors as values\n",
    "    '''\n",
    "    vecs = defaultdict(lambda: np.zeros(shape=(300, 1)))\n",
    "    with open(file) as f:\n",
    "        lines = f.readlines()\n",
    "        for word_and_vec in lines:\n",
    "            elems = word_and_vec.strip().split(' ')\n",
    "            word = elems[0]\n",
    "            vec = np.array(elems[1:], dtype=float)\n",
    "            vecs[word] = vec\n",
    "    return vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-06T18:37:02.535322Z",
     "start_time": "2018-12-06T18:37:02.517443Z"
    }
   },
   "outputs": [],
   "source": [
    "def split_dictionary():\n",
    "    \"\"\"\n",
    "    firstly, I split the dictionary into a wordlist and a matrix.\n",
    "    returns a list of words and \n",
    "    a 2d matrix of the normalized word vectors\n",
    "\n",
    "    :returns:               the words and matrix associated with\n",
    "                            the glove dictionary\n",
    "    \"\"\"\n",
    "    wordlist = []\n",
    "    matrix = []\n",
    "    with open(glove_file) as f:\n",
    "        lines = f.readlines()\n",
    "        for word_and_vec in lines:\n",
    "            wordvec = np.array([float(x) for x in word_and_vec.split()[1:]])\n",
    "            matrix.append(wordvec / np.linalg.norm(wordvec))\n",
    "            wordlist.append(word_and_vec.split()[0])\n",
    "        matrix = np.array(matrix)\n",
    "    return wordlist, matrix\n",
    "\n",
    "\n",
    "def unique_words(train_df):\n",
    "    \"\"\"\n",
    "    I then obtain the unique words that appear in the search_term.\n",
    "\n",
    "    :param train_df:        the training set Pandas dataframe\n",
    "    :returns:               a list of unique words from search terms\n",
    "                            that have been stripped of numbers, symbols, etc.\n",
    "    \"\"\"\n",
    "    cleaned = list(train_df['cleaned_terms'])\n",
    "    all_words = []\n",
    "    for t in cleaned:\n",
    "        all_words += t.split(' ')\n",
    "\n",
    "    return list(set(all_words))[1:]\n",
    "\n",
    "\n",
    "def find_nearest_neighbors(filename, cleaned_set, matrix, wordlist, dictionary):\n",
    "    \"\"\"\n",
    "    here I count the cos_distance of each word that is in the cleaned_set.\n",
    "    the output file looks like (each line): w0, w1, w2, w3, w4,\n",
    "    i didn't print the distance, just the neighbour words\n",
    "    this will take couple of minutes.\n",
    "\n",
    "    :param filename:        a string representing the filename to write to\n",
    "    :param clenaed_set:     a list of search terms that have \n",
    "                            been stripped of numbers, symbols, etc.\n",
    "    :param matrix:          a 2d Numpy array of the word vectors in wordlist\n",
    "    :param wordlist:        a list of words from the glove dictionary\n",
    "    :param dictionary:      a dictionary with words as keys \n",
    "                            and 300d vectors as values\n",
    "    \"\"\"\n",
    "    output_string = ''\n",
    "\n",
    "    for word in cleaned_set:\n",
    "        dots = matrix.dot(dictionary[word])\n",
    "        close_index_vec = np.argsort(dots)\n",
    "        for i in range(5):\n",
    "            output_string += wordlist[int(close_index_vec[-1-i])] + ','\n",
    "        output_string += '\\n'\n",
    "\n",
    "    f = open(filename, \"w\")\n",
    "    f.write(output_string)\n",
    "    f.close()\n",
    "\n",
    "\n",
    "def get_all_terms_neighbors(dictionary, cleaned):\n",
    "    \"\"\"\n",
    "    terms_neighbour is the list which stores the top 4 neighbours of each searching_terms. \n",
    "    for example, if the searching term is: cleaned[0]='w1_w2', \n",
    "    then the terms_neighbour[0]='n11_n12_n13_n14_n21_n22_n23_n24'.\n",
    "\n",
    "    :param dictionary:      a dictionary\n",
    "    :param cleaned:         a list of search terms that have\n",
    "                            been stripped of numbers, symbols, etc.\n",
    "    :returns:               a list of concatenated words that are neighbors\n",
    "                            of the 'cleaned' terms\n",
    "    \"\"\"\n",
    "    terms_neighbour = []\n",
    "    for i in range(len(cleaned)):\n",
    "        neighbours = ''\n",
    "        if cleaned[i] != '':\n",
    "            words = cleaned[i].split(' ')\n",
    "            for w in words:\n",
    "                neighbours = neighbours + dictionary[w] + ' '\n",
    "        terms_neighbour.append(neighbours)\n",
    "    return terms_neighbour\n",
    "\n",
    "\n",
    "def build_dictionary(file):\n",
    "    \"\"\"\n",
    "    based on the above output file, I then built a dictionary;\n",
    "    this dictionary stores each word (as key) \n",
    "    with its top 4 neighbour words (as value) \n",
    "\n",
    "    :param file:            the file containing the list of strings of neighbors\n",
    "    :returns:               a dictionary with words as keys \n",
    "                            and 4 neighbors of that word as values\n",
    "    \"\"\"\n",
    "    k_dic = defaultdict(lambda: '')\n",
    "    with open(file) as f:\n",
    "        lines = f.readlines()\n",
    "        for line in lines:\n",
    "            words = line.strip().split(',')\n",
    "            k_dic[words[0]] = words[1] + ' ' + \\\n",
    "                words[2] + ' ' + words[3] + ' ' + words[4]\n",
    "    return k_dic\n",
    "\n",
    "\n",
    "def clean_term_in_doc(terms, title):\n",
    "    \"\"\"\n",
    "    This cleans the given terms in the specified document\n",
    "\n",
    "    :param terms:           a list of unique search terms\n",
    "    :param title:           a list of titles of products\n",
    "    :return:                a list of the counts of the \n",
    "                            cleaned terms within a product's title\n",
    "    \"\"\"\n",
    "    count = np.zeros(len(terms))\n",
    "    for i in range(len(terms)):\n",
    "        if not pd.isnull(terms[i]):\n",
    "            title[i] = title[i].lower()\n",
    "            for term in terms[i].split(' '):\n",
    "                if term in title[i].split(' '):\n",
    "                    count[i] += 1\n",
    "    return count\n",
    "\n",
    "\n",
    "def get_length(column):\n",
    "    \"\"\"\n",
    "    This calculates and returns the number of words\n",
    "    for each row in a specified column\n",
    "\n",
    "    :param column:          the feature/attribute which\n",
    "                            will have its words counted\n",
    "    :returns:               a column with the count of \n",
    "                            words in each string\n",
    "    \"\"\"\n",
    "    length = np.zeros(len(column))\n",
    "    for index in range(len(column)):\n",
    "        if not pd.isnull(column[index]):\n",
    "            length[index] = len(column[index].split(' '))\n",
    "    return length\n",
    "\n",
    "\n",
    "def tokenize(text):\n",
    "    \"\"\"\n",
    "    Tokenize text and return a non-unique list of tokenized words\n",
    "    found in the text. Normalize to lowercase, strip punctuation,\n",
    "    remove stop words, drop words of length < 3, strip digits.\n",
    "\n",
    "    :param text:            a string\n",
    "    :returns:               the same string stripped of numbers,\n",
    "                            tabs, newline characters, and punctuation\n",
    "    \"\"\"\n",
    "    stops = list(stop_words.ENGLISH_STOP_WORDS)\n",
    "    text = text.lower()\n",
    "    regex = re.compile('[' + re.escape(string.punctuation) + '0-9\\\\r\\\\t\\\\n]')\n",
    "    # delete stuff but leave at least a space to avoid clumping together\n",
    "    nopunct = regex.sub(\" \", text)\n",
    "    words = nopunct.split(\" \")\n",
    "    # ignore a, an, to, at, be, ...\n",
    "    words = [w for w in words if (len(w) > 2 and (w not in stops))]\n",
    "    return words\n",
    "\n",
    "\n",
    "def stemmed(words):\n",
    "    \"\"\"\n",
    "    Stem a tokenized text and return a non-unique list of stemmed words\n",
    "    found in the text. This is based on the output of function\n",
    "    tokenize(text).\n",
    "\n",
    "    :param text:            a list of tokenized words\n",
    "    :returns:               a list of stemmed words\n",
    "    \"\"\"\n",
    "    stemmer = PorterStemmer()\n",
    "    return [stemmer.stem(w) for w in words]\n",
    "\n",
    "\n",
    "def lemmatized(words):\n",
    "    \"\"\"\n",
    "    lemmatize a tokenized text and return a non-unique list of stemmed words\n",
    "    found in the text. This is based on the output of function\n",
    "    tokenize(text).\n",
    "\n",
    "    :param text:            a list of tokenized words\n",
    "    :returns:               a list of lemmatized words\n",
    "    \"\"\"\n",
    "    lemmatized_words = [nltk.stem.WordNetLemmatizer().lemmatize(w)\n",
    "                        for w in words]\n",
    "    return lemmatized_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-06T18:37:03.471853Z",
     "start_time": "2018-12-06T18:37:03.445671Z"
    }
   },
   "outputs": [],
   "source": [
    "def tokenizer(text):\n",
    "    return stemmed(tokenize(text))\n",
    "\n",
    "\n",
    "def attrib_stack(attributes):\n",
    "    \"\"\"\n",
    "    Aggregate all the features of a product into a single description\n",
    "    and return a dataframe with product id and description that is tokenized.\n",
    "    \"\"\"\n",
    "    attributes['value'] = attributes['value'].apply(lambda x: str(x))\n",
    "    attrib_per_product = attributes.groupby(\n",
    "        'product_uid').agg(lambda x: x.tolist())\n",
    "    attrib_per_product = attrib_per_product.reset_index()\n",
    "    attrib_per_product['value'] = attrib_per_product['value'].apply(\n",
    "        lambda x: ','.join(x))\n",
    "    attrib_per_product['value'] = attrib_per_product['value'].apply(\n",
    "        lambda x: tokenizer(x))\n",
    "    attrib_per_product['value'] = attrib_per_product['value'].apply(\n",
    "        lambda x: ','.join(x))\n",
    "    attrib_per_product.to_csv('attrib_per_product.csv')\n",
    "    attrib_per_product = pd.read_csv('attrib_per_product.csv')\n",
    "    attrib_per_product = attrib_per_product.drop('Unnamed: 0', axis=1)\n",
    "    return attrib_per_product\n",
    "\n",
    "\n",
    "def join_attrib(train, attrib_per_product):\n",
    "    \"\"\"\n",
    "    Join the aggregated attributes to the train dataframe\n",
    "    \"\"\"\n",
    "    train = train.set_index('product_uid').join(\n",
    "        attrib_per_product.set_index('product_uid'))\n",
    "    train = train.reset_index()\n",
    "    attrib_per_product = attrib_per_product.reset_index()\n",
    "    return train, attrib_per_product\n",
    "\n",
    "\n",
    "def search_term_in_attrib(train):\n",
    "    \"\"\"\n",
    "    Convert the search term (stemmed) and attributes description to a set of words\n",
    "    and find the number of common terms between both in the column search_term_in_attrib.\n",
    "    \"\"\"\n",
    "    train['value'].fillna('', inplace=True)\n",
    "    train['value'] = train['value'].apply(lambda x: set(x.split(',')))\n",
    "    train['search_term_split'] = train['search_term'].apply(\n",
    "        lambda x: set(tokenizer(x)))\n",
    "    search_term_in_attrib = []\n",
    "    for i in range(len(train)):\n",
    "        p = len(train['search_term_split'][i].intersection(train['value'][i]))\n",
    "        search_term_in_attrib.append(p)\n",
    "    train['search_term_in_attrib'] = search_term_in_attrib\n",
    "    return train\n",
    "\n",
    "\n",
    "def color_df(attributes, train):\n",
    "    \"\"\"\n",
    "    Find the attributes for color per product, join it with train data and \n",
    "    check for match in the search term\n",
    "    \"\"\"\n",
    "    attrib_col = attributes[attributes['name'].apply(\n",
    "        lambda x: 'color' in str(x).lower())]\n",
    "    attrib_col = attrib_col.groupby('product_uid').agg(lambda x: x.tolist())\n",
    "    attrib_col = attrib_col.drop('name', axis=1)\n",
    "    attrib_col = attrib_col.reset_index()\n",
    "    attrib_col = attrib_col.rename(columns={'value': 'color'})\n",
    "\n",
    "    attrib_col['color'] = attrib_col['color'].apply(lambda x: ','.join(x))\n",
    "    attrib_col['color'] = attrib_col['color'].apply(\n",
    "        lambda x: ','.join(x.replace('/', '').replace(' ', ',').split(',')).replace(',,', ','))\n",
    "\n",
    "    train = train.set_index('product_uid').join(\n",
    "        attrib_col.set_index('product_uid'))\n",
    "    train = train.reset_index()\n",
    "    attrib_col = attrib_col.reset_index()\n",
    "    train['color'].fillna('', inplace=True)\n",
    "    train['search_term'].fillna('', inplace=True)\n",
    "    train['color'] = train['color'].apply(lambda x: set(x.split(',')))\n",
    "\n",
    "    color_in_search_term = []\n",
    "    for i in range(len(train)):\n",
    "        p = len(train['color'][i].intersection(train['search_term_split'][i]))\n",
    "        color_in_search_term.append(p)\n",
    "    train['color_in_search_term'] = color_in_search_term\n",
    "\n",
    "    return train\n",
    "\n",
    "\n",
    "def search_title_lev_dist(train):\n",
    "    \"\"\"\n",
    "    Calculate Levenshtein distance between search term and the product title\n",
    "    \"\"\"\n",
    "    train.to_csv('train_with_search_in_attrib.csv')\n",
    "    train = pd.read_csv('train_with_search_in_attrib.csv')\n",
    "    train = train.drop(['Unnamed: 0'], axis=1)\n",
    "    train['product_title_clean'] = train['product_title'].apply(\n",
    "        lambda x: list(set(tokenize(x))))\n",
    "    train['search_term'].fillna('', inplace=True)\n",
    "    train['search_term_split'] = train['search_term'].apply(\n",
    "        lambda x: x.split(' '))\n",
    "\n",
    "    p = []\n",
    "    for i in range(len(train)):\n",
    "        q = []\n",
    "        if len(train['search_term_split'][i][0]) > 0:\n",
    "            for j in range(len(train['search_term_split'][i])):\n",
    "                for k in range(len(train['product_title_clean'][i])):\n",
    "                    if train['search_term_split'][i][j] in train['product_title_clean'][i][k]:\n",
    "                        q.append((train['product_title_clean'][i]\n",
    "                                  [k], train['product_title_clean'][i][k]))\n",
    "                        continue\n",
    "                    elif train['search_term_split'][i][j][0] == train['product_title_clean'][i][k][0]:\n",
    "                        q.append((train['search_term_split'][i][j],\n",
    "                                  train['product_title_clean'][i][k]))\n",
    "        p.append(q)\n",
    "\n",
    "    l = []\n",
    "    for i in range(len(p)):\n",
    "        q = []\n",
    "        for j in range(len(p[i])):\n",
    "            q.append(distance(p[i][j][0], p[i][j][1]))\n",
    "        l.append(q)\n",
    "\n",
    "    m = []\n",
    "    for q in l:\n",
    "        if q == []:\n",
    "            m.append(1000)\n",
    "        else:\n",
    "            m.append(min(q))\n",
    "\n",
    "    train['min_levenstein_dist_title'] = m\n",
    "\n",
    "    return train\n",
    "\n",
    "\n",
    "def search_brand_lev_dist(train, attributes):\n",
    "    \"\"\"\n",
    "    Filter out the brand from attributes, join it with train data.\n",
    "    Calculate Levenshtein distance between search term and the brand\n",
    "    \"\"\"\n",
    "    attr_brand = attributes[(attributes['name'].str.lower().str.contains(\n",
    "        'brand') == True) & attributes['value'].notnull()]\n",
    "    attr_brand = attr_brand.drop('name', axis=1)\n",
    "    attr_brand = attr_brand.rename(columns={'value': 'brand'})\n",
    "    attr_brand['product_uid'] = attr_brand['product_uid'].apply(\n",
    "        lambda x: int(x))\n",
    "\n",
    "    d = defaultdict(list)\n",
    "    p = list(attr_brand['product_uid'])\n",
    "    b = list(attr_brand['brand'])\n",
    "    for i in range(len(p)):\n",
    "        if p[i] not in d:\n",
    "            d[p[i]] = tokenize(b[i])\n",
    "        else:\n",
    "            continue\n",
    "    train['brand'] = train['product_uid'].apply(lambda x: d[x])\n",
    "    train['brand'].fillna('', inplace=True)\n",
    "    train['search_term'].fillna('', inplace=True)\n",
    "    train['search_term_split'] = train['search_term'].apply(\n",
    "        lambda x: x.split(' '))\n",
    "\n",
    "    p = []\n",
    "    for i in range(len(train)):\n",
    "        q = []\n",
    "        if len(train['search_term_split'][i][0]) > 0:\n",
    "            for j in range(len(train['search_term_split'][i])):\n",
    "                for k in range(len(train['brand'][i])):\n",
    "                    if train['search_term_split'][i][j] in train['brand'][i][k]:\n",
    "                        q.append((train['brand'][i][k], train['brand'][i][k]))\n",
    "                        continue\n",
    "                    elif train['search_term_split'][i][j][0] == train['brand'][i][k][0]:\n",
    "                        q.append((train['search_term_split']\n",
    "                                  [i][j], train['brand'][i][k]))\n",
    "        p.append(q)\n",
    "\n",
    "    l = []\n",
    "    for i in range(len(p)):\n",
    "        q = []\n",
    "        for j in range(len(p[i])):\n",
    "            q.append(distance(p[i][j][0], p[i][j][1]))\n",
    "        l.append(q)\n",
    "\n",
    "    m = []\n",
    "    for q in l:\n",
    "        if q == []:\n",
    "            m.append(1000)\n",
    "        else:\n",
    "            m.append(min(q))\n",
    "\n",
    "    train['min_levenstein_dist_brand'] = m\n",
    "\n",
    "    return train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-06T18:37:04.307399Z",
     "start_time": "2018-12-06T18:37:04.296360Z"
    }
   },
   "outputs": [],
   "source": [
    "def letter_prob(phrases):\n",
    "    \"\"\"\n",
    "    :param phrases:         a list of strings of text\n",
    "    :returns:               a list of dictionaries of probabilities for characters in the text \n",
    "    \"\"\"\n",
    "    letter_counters = []\n",
    "    for phrase in phrases:\n",
    "        letter_count = defaultdict(lambda: 0)\n",
    "        for char in phrase:\n",
    "            if char.isalpha():\n",
    "                if char in letter_count:\n",
    "                    letter_count[char] += 1\n",
    "                else:\n",
    "                    letter_count[char] = 1\n",
    "        letter_counters.append(letter_count)\n",
    "\n",
    "        total_count = float(sum(list(letter_count.values())))\n",
    "\n",
    "        for key in letter_count.keys():\n",
    "            letter_count[key] = letter_count[key] / total_count\n",
    "\n",
    "    return letter_counters\n",
    "\n",
    "\n",
    "def calculate_entropy(probs_list):\n",
    "    \"\"\"\n",
    "    :param probs_list:      a list of dictionaries in which the values are probabilities\n",
    "    :returns:               a list of entropies calculated for the given probs_list\n",
    "    \"\"\"\n",
    "    entropies = []\n",
    "    for distribution in probs_list:\n",
    "        entropy = 0\n",
    "        for key in distribution.keys():\n",
    "            entropy += distribution[key] * math.log2(distribution[key])\n",
    "        entropy *= -1\n",
    "        entropies.append(entropy)\n",
    "    return entropies\n",
    "\n",
    "\n",
    "def longest_common_subsequence(X, Y):\n",
    "    \"\"\"\n",
    "    :param X:               a list of strings of text\n",
    "    :param Y:               a list of strings of text\n",
    "    :returns:               a list of the integer length of the longest common subsequence \n",
    "                            between the strings\n",
    "    \"\"\"\n",
    "    lcs = []\n",
    "\n",
    "    for idx, x in enumerate(X):\n",
    "        m = len(x)\n",
    "        n = len(Y[idx])\n",
    "\n",
    "        L = [[None]*(n+1) for i in range(m+1)]\n",
    "\n",
    "        for i in range(m+1):\n",
    "            for j in range(n+1):\n",
    "                if i == 0 or j == 0:\n",
    "                    L[i][j] = 0\n",
    "                elif x[i-1] == Y[idx][j-1]:\n",
    "                    L[i][j] = L[i-1][j-1]+1\n",
    "                else:\n",
    "                    L[i][j] = max(L[i-1][j], L[i][j-1])\n",
    "        lcs.append(L[m][n])\n",
    "\n",
    "    return lcs\n",
    "\n",
    "\n",
    "def calculate_jaccard_index(text_1, text_2):\n",
    "    \"\"\"\n",
    "    :param text_1:         a list of strings of text\n",
    "    :param text_2:         a second list of strings of text\n",
    "    :returns:              a list of jaccard indices (intersection of words / union of words)\n",
    "                           between the strings of text provided\n",
    "    \"\"\"\n",
    "    jaccard_indices = []\n",
    "    for text in zip(text_1, text_2):\n",
    "        tokens_1 = set(tokenize(text[0]))\n",
    "        tokens_2 = set(tokenize(text[1]))\n",
    "        intersection_ = tokens_1.intersection(tokens_2)\n",
    "        union_ = tokens_1.union(tokens_2)\n",
    "        jaccard_indices.append(\n",
    "            len(list(intersection_)) / float(len(list(union_))))\n",
    "    return jaccard_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-06T18:37:05.149263Z",
     "start_time": "2018-12-06T18:37:05.131543Z"
    }
   },
   "outputs": [],
   "source": [
    "def jaro(s, t):\n",
    "    s_len = len(s)\n",
    "    t_len = len(t)\n",
    "\n",
    "    if s_len == 0 and t_len == 0:\n",
    "        return 1\n",
    "\n",
    "    match_distance = (max(s_len, t_len) // 2) - 1\n",
    "\n",
    "    s_matches = [False] * s_len\n",
    "    t_matches = [False] * t_len\n",
    "\n",
    "    matches = 0\n",
    "    transpositions = 0\n",
    "\n",
    "    for i in range(s_len):\n",
    "        start = max(0, i-match_distance)\n",
    "        end = min(i+match_distance+1, t_len)\n",
    "\n",
    "        for j in range(start, end):\n",
    "            if t_matches[j]:\n",
    "                continue\n",
    "            if s[i] != t[j]:\n",
    "                continue\n",
    "            s_matches[i] = True\n",
    "            t_matches[j] = True\n",
    "            matches += 1\n",
    "            break\n",
    "    if matches == 0:\n",
    "        return 0\n",
    "\n",
    "    k = 0\n",
    "    for i in range(s_len):\n",
    "        if not s_matches[i]:\n",
    "            continue\n",
    "        while not t_matches[k]:\n",
    "            k += 1\n",
    "        if s[i] != t[k]:\n",
    "            transpositions += 1\n",
    "        k += 1\n",
    "\n",
    "    return ((matches / s_len) +\n",
    "            (matches / t_len) +\n",
    "            ((matches - transpositions/2) / matches)) / 3\n",
    "\n",
    "\n",
    "def getJaroScoreOnDocs(query, long_text):\n",
    "    # transform query and long_text to list of words.\n",
    "    query_ls = query.split()\n",
    "    long_text_ls = long_text.split()\n",
    "\n",
    "    total_J_score = 0\n",
    "    for i in query_ls:\n",
    "        j_score_in_i = sum([jaro(i, j)\n",
    "                            for j in long_text_ls if jaro(i, j) > 0.83])\n",
    "        total_J_score += j_score_in_i\n",
    "\n",
    "    return total_J_score\n",
    "\n",
    "\n",
    "def createJaroCol(df, query_col_name, text_col_name, new_col_name):\n",
    "    # Could combine title and description as a unit to compute Jaro score.\n",
    "    # It will be higher but as one score, easy to compute.\n",
    "    # compute all jscore in a list\n",
    "    j_score_ls = []\n",
    "    for i in range(len(df)):\n",
    "        query = df[query_col_name].iloc[i]\n",
    "        long_text = df[text_col_name].iloc[i]\n",
    "        j_score = getJaroScoreOnDocs(query, long_text)\n",
    "        j_score_ls.append(j_score)\n",
    "    df[new_col_name] = j_score_ls\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "def smith_waterman(a: str, b: str, alignment_score: float = 1, gap_cost: float = 1) -> float:\n",
    "    \"\"\"\n",
    "    Compute the Smith-Waterman alignment score for two strings.\n",
    "    See https://en.wikipedia.org/wiki/Smith%E2%80%93Waterman_algorithm#Algorithm\n",
    "    This implementation has a fixed gap cost (i.e. extending a gap is considered\n",
    "    free). In the terminology of the Wikipedia description, W_k = {c, c, c, ...}.\n",
    "    This implementation also has a fixed alignment score, awarded if the relevant\n",
    "    characters are equal.\n",
    "    Kinda slow, especially for large (50+ char) inputs.\n",
    "    \"\"\"\n",
    "    # H holds the alignment score at each point, computed incrementally\n",
    "    H = np.zeros((len(a) + 1, len(b) + 1))\n",
    "    for i in range(1, len(a) + 1):\n",
    "        for j in range(1, len(b) + 1):\n",
    "            # The score for substituting the letter a[i-1] for b[j-1]. Generally low\n",
    "            # for mismatch, high for match.\n",
    "            match = H[i-1, j-1] + (alignment_score if a[i-1] == b[j-1] else 0)\n",
    "\n",
    "            # The scores for for introducing extra letters in one of the strings (or\n",
    "            # by symmetry, deleting them from the other).\n",
    "            delete = H[1:i, j].max() - gap_cost if i > 1 else 0\n",
    "            insert = H[i, 1:j].max() - gap_cost if j > 1 else 0\n",
    "            H[i, j] = max(match, delete, insert, 0)\n",
    "    # The highest score is the best local alignment.\n",
    "    # For our purposes, we don't actually care _what_ the alignment was, just how\n",
    "    # aligned the two strings were.\n",
    "    return H.max()\n",
    "\n",
    "\n",
    "def getSWscore(query, long_text):\n",
    "    \"\"\"\n",
    "    param: query is the search query as a string.\n",
    "    param: text is the long text to compute the similarity.\n",
    "    return the number of significant alignment strings in both text. ie. the number of similar terms in query and long_text.\n",
    "    \"\"\"\n",
    "    query_ls = query.split()\n",
    "    long_text_ls = long_text.split()\n",
    "\n",
    "    sw_score = []\n",
    "    for i in query_ls:\n",
    "        score = sum([smith_waterman(i, j)\n",
    "                     for j in long_text_ls if smith_waterman(i, j) >= 4.0])\n",
    "        sw_score.append(score)\n",
    "    return round(sum(sw_score)/5)\n",
    "\n",
    "\n",
    "def createSWscoreCol(df, query_col_name, long_text_col_name, new_col_name):\n",
    "    first_col = df[query_col_name]\n",
    "    second_col = df[long_text_col_name]\n",
    "\n",
    "    score_ls = []\n",
    "    for i in range(len(first_col)):\n",
    "        score_ls.append(getSWscore(first_col.iloc[i], second_col.iloc[i]))\n",
    "    df[new_col_name] = score_ls\n",
    "    return df\n",
    "\n",
    "\n",
    "def computeNCD(string1, string2):\n",
    "    \"\"\"\n",
    "    params: string1 is the query term\n",
    "    params: string2 is the word in long-text, like title, description.\n",
    "    \"\"\"\n",
    "    # Get concated strings and transform to bytes-like object for lzma.compress.\n",
    "    concat_str = string1+string2\n",
    "    string1 = bytes(string1, 'utf-8')\n",
    "    string2 = bytes(string2, 'utf-8')\n",
    "    concat_str = bytes(concat_str, 'utf-8')\n",
    "\n",
    "    # Get the compressed file for each string.\n",
    "    str1_comp = lzma.compress(string1)  # compress file 1\n",
    "    str2_comp = lzma.compress(string2)  # compress file 2\n",
    "    concat_str_comp = lzma.compress(concat_str)  # compress file concatenated\n",
    "\n",
    "    # magic happens here\n",
    "    ncd = (len(concat_str_comp) - min(len(str1_comp), len(str2_comp))) / \\\n",
    "        max(len(str1_comp), len(str2_comp))\n",
    "\n",
    "    return ncd\n",
    "\n",
    "\n",
    "def createNCDCol(df, search_name, long_text_name, new_col_name):\n",
    "    NCD_score_ls = []\n",
    "    for i in range(len(df)):\n",
    "        str1 = df[search_name].iloc[i]\n",
    "        str2 = df[long_text_name].iloc[i]\n",
    "        NCD_score_ls.append(np.mean([computeNCD(a, b)\n",
    "                                     for a in str1.split() for b in str2.split()]))\n",
    "    df[new_col_name] = NCD_score_ls\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-06T18:37:06.405498Z",
     "start_time": "2018-12-06T18:37:06.399533Z"
    }
   },
   "outputs": [],
   "source": [
    "PARTIALS = False\n",
    "\n",
    "\n",
    "def gettext(xmltext):\n",
    "    \"\"\"\n",
    "    Parse xmltext and return the text from <title> and <text> tags\n",
    "    \"\"\"\n",
    "\n",
    "    # ensure there are no weird char\n",
    "    xmltext = xmltext.encode('ascii', 'ignore')\n",
    "    root = ET.fromstring(xmltext)\n",
    "    text = []\n",
    "    for elem in root.iterfind('title'):\n",
    "        text.append(elem.text)\n",
    "    for elem in root.iterfind('.//text/*'):\n",
    "        text.append(elem.text)\n",
    "    text = ' '.join(text)\n",
    "\n",
    "    return text\n",
    "\n",
    "\n",
    "def compute_tfidf(corpus):\n",
    "    \"\"\"\n",
    "    Create and return a TfidfVectorizer object after training it on\n",
    "    the list of articles pulled from the corpus dictionary. The\n",
    "    corpus argument is a dictionary mapping file name to xml text.\n",
    "    \"\"\"\n",
    "    tfidf = TfidfVectorizer(input='content',\n",
    "                            analyzer='word',\n",
    "                            preprocessor=gettext,\n",
    "                            tokenizer=tokenizer,\n",
    "                            stop_words='english',\n",
    "                            decode_error='ignore')\n",
    "    tfidf.fit(list(corpus.values()))\n",
    "\n",
    "    return tfidf\n",
    "\n",
    "\n",
    "def add_prod_description_column(train):\n",
    "    \"\"\"\n",
    "    Add the product description from product df to train df.\n",
    "    Concatenate Title and description to form total_description column.\n",
    "    \"\"\"\n",
    "    train['total_description'] = train['product_title'] + \\\n",
    "        train['product_description']\n",
    "    return train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-06T18:37:07.338553Z",
     "start_time": "2018-12-06T18:37:07.329662Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_words(x):\n",
    "    \"\"\"\n",
    "    Remove the tfidf scores and return only the top tfidf words\n",
    "    \"\"\"\n",
    "    q = []\n",
    "    for i in range(len(x)):\n",
    "        if x[i][0] != []:\n",
    "            q.append(x[i][0])\n",
    "    return q\n",
    "\n",
    "\n",
    "def add_tfidf_col(train):\n",
    "    train['tfidf'] = train['tfidf'].apply(lambda x: get_words(x))\n",
    "    return train\n",
    "\n",
    "\n",
    "def num_stop_words(x):\n",
    "    stops = list(stop_words.ENGLISH_STOP_WORDS)\n",
    "    return len([w for w in x if w in stops])\n",
    "\n",
    "\n",
    "def find_tfidf_words_in_search(train):\n",
    "    train['search_term_split'] = train['search_term'].apply(\n",
    "        lambda x: tokenizer(x))\n",
    "    p = train['search_term_split']\n",
    "    q = train['tfidf']\n",
    "    l = []\n",
    "    for i in range(len(p)):\n",
    "        l.append(len(set(p[i]).intersection(set(q[i]))))\n",
    "    train['tfidf_search_common'] = l\n",
    "\n",
    "    return train\n",
    "\n",
    "\n",
    "def num_attrib_per_product(attributes):\n",
    "    \"\"\"\n",
    "    Find the number of attributes per product\n",
    "    \"\"\"\n",
    "    attributes['value'] = attributes['value'].apply(\n",
    "        lambda x: tokenizer(str(x)))\n",
    "    attributes['value'] = attributes['value'].apply(lambda x: ','.join(x))\n",
    "    attrib_per_product = attributes.groupby(\n",
    "        'product_uid').agg(lambda x: x.tolist())\n",
    "    attrib_per_product = attrib_per_product.reset_index()\n",
    "    attrib_per_product['value'] = attrib_per_product['value'].apply(\n",
    "        lambda x: ','.join(x).replace(',', ' '))\n",
    "    attrib_per_product['num_attrib'] = attrib_per_product['name'].apply(\n",
    "        lambda x: len(x))\n",
    "    attrib_per_product['value'].fillna('', inplace=True)\n",
    "    attrib_per_product.rename(columns={'value': 'attribs'})\n",
    "    attrib_per_product['product_uid'] = attrib_per_product['product_uid'].apply(\n",
    "        lambda x: int(x))\n",
    "\n",
    "    return attrib_per_product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-06T18:37:14.317092Z",
     "start_time": "2018-12-06T18:37:14.311654Z"
    }
   },
   "outputs": [],
   "source": [
    "def find_n_tfidf_highest_scores(train_set, n):\n",
    "    tfidf = TfidfVectorizer(input='content',\n",
    "                            analyzer='word',\n",
    "                            tokenizer=tokenizer,\n",
    "                            stop_words='english',\n",
    "                            decode_error='ignore')\n",
    "    tfidf.fit(train_set['total_description'])\n",
    "\n",
    "    p = []\n",
    "    total_description = list(train_set['total_description'])\n",
    "    for i in range(len(train_set)):\n",
    "        response = tfidf.transform([total_description[i]])\n",
    "        feature_names = tfidf.get_feature_names()\n",
    "        col = response.nonzero()[1]\n",
    "        t = []\n",
    "        t = [(feature_names[col], response[0, col])\n",
    "             for col in response.nonzero()[1] if response[0, col] >= 0.09]\n",
    "        t.sort(key=lambda x: x[1], reverse=True)\n",
    "        p.append(t[0:n])\n",
    "\n",
    "    train_set['tfidf'] = p\n",
    "    return train_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-06T18:37:15.744541Z",
     "start_time": "2018-12-06T18:37:15.740695Z"
    }
   },
   "outputs": [],
   "source": [
    "def add_word_count_features(train_df):\n",
    "    train_df['num_words_in_description'] = train_df['total_description'].apply(\n",
    "        lambda x: len(tokenize(x)))\n",
    "    train_df['num_stop_words'] = train_df['search_term'].apply(\n",
    "        lambda x: num_stop_words(x.split(' ')))\n",
    "    train_df['num_search_words'] = train_df['search_term'].apply(\n",
    "        lambda x: len(x.split(' ')))\n",
    "    return train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-06T18:37:16.782037Z",
     "start_time": "2018-12-06T18:37:16.777981Z"
    }
   },
   "outputs": [],
   "source": [
    "def add_num_attrib_per_prod_column(train_df, attributes_df):\n",
    "    attrib_per_product = num_attrib_per_product(attributes_df)\n",
    "    train_df = train_df.set_index('product_uid').join(\n",
    "        attrib_per_product.set_index('product_uid'),\n",
    "        lsuffix='', rsuffix='_r')\n",
    "    train_df = train_df.reset_index()\n",
    "    attrib_per_product = attrib_per_product.reset_index()\n",
    "\n",
    "    train_df = train_df.drop('name_r', 1)\n",
    "    train_df = train_df.drop('value_r', 1)\n",
    "    train_df['num_attrib'] = train_df['num_attrib'].fillna(0)\n",
    "\n",
    "    return train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-07T01:27:06.958901Z",
     "start_time": "2018-12-07T01:27:06.953109Z"
    }
   },
   "outputs": [],
   "source": [
    "def getAllNumericalCols(all_features):\n",
    "    \"\"\"\n",
    "    param: all_features is a data frame containning all features.\n",
    "    output: column names of all numerical features.\n",
    "    \"\"\"\n",
    "    col_names = all_features.columns.tolist()\n",
    "    all_num_ind = [15]+list(range(25, len(col_names)))\n",
    "    all_num_col = [col_names[i] for i in all_num_ind]\n",
    "\n",
    "    return all_num_col\n",
    "\n",
    "\n",
    "def getSimilarityCols(all_num_features):\n",
    "    \"\"\"\n",
    "    param: all_features is a data frame containning all numerical features.\n",
    "    output: column names of all similarity features.\n",
    "    \"\"\"\n",
    "    all_similarity_features = [all_num_features.columns.tolist(\n",
    "    )[i] for i in [7, 8, 11, 12, 13, 14, 15, 16, 17, 18, 19]]\n",
    "    return all_similarity_features\n",
    "\n",
    "\n",
    "def getCountAndOtherCols(all_similarity_features, all_num_features):\n",
    "    \"\"\"\n",
    "    return the column names of all count features and len_Entropy columns.\n",
    "    \"\"\"\n",
    "    all_other_num_cols = set(all_num_features.columns.tolist()).difference(\n",
    "        set(all_similarity_features.columns.tolist()))\n",
    "    col_has_in = [i for i in all_other_num_cols if \"in\" in i]\n",
    "    len_H_features = list(set(all_other_num_cols).difference(set(col_has_in)))\n",
    "\n",
    "    return col_has_in, len_H_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-06T18:37:18.582780Z",
     "start_time": "2018-12-06T18:37:18.569475Z"
    }
   },
   "outputs": [],
   "source": [
    "def feature_engineering(train_df, products_df, dictionary):\n",
    "    \"\"\"\n",
    "    Adds the following features to the training set dataframe: \n",
    "    * clean_length: the count of words in the 'cleaned' search terms\n",
    "    * title_length: the count of words in the 'cleaned' title\n",
    "    * desc_length: the count of words in the 'cleaned' description\n",
    "    * clean_terms_in_title: the number of time \n",
    "    any of the words in clean_terms appears in the title\n",
    "    * clean_terms_in_desc: the number of time \n",
    "    any of the words in clean_terms appears in the description\n",
    "    * neighbours_in_title: the count of the appearance of the \n",
    "    words closest to the search terms in the title\n",
    "    * neighbours_in_desc: the count of the appearance of the \n",
    "    words closest to the search terms in the description\n",
    "\n",
    "    :param train_df:        the training set Pandas dataframe\n",
    "    :param products_df:     the product descriptions dataframe\n",
    "    :param dictionary:      the glove dictionary\n",
    "    :returns:               the modified dataframe with the additional features\n",
    "    \"\"\"\n",
    "    # join the dataframes together\n",
    "    train_df = train_df.set_index('product_uid').join(\n",
    "        products_df.set_index('product_uid'))\n",
    "    train_df = train_df.reset_index()\n",
    "\n",
    "    # \"clean\" the search terms of numbers and stop words\n",
    "    search_terms = train_df['search_term']\n",
    "    cleaned_terms = [' '.join(tokenize(search_term))\n",
    "                     for search_term in search_terms]\n",
    "    train_df['cleaned_terms'] = cleaned_terms\n",
    "\n",
    "    cleaned = list(train_df['cleaned_terms'])\n",
    "    title = list(train_df['product_title'])\n",
    "    desc = list(train_df['product_description'])\n",
    "\n",
    "    # stem the search terms, title, and descriptions\n",
    "    stemmed_terms = [' '.join(stemmed(tokenize(search_term)))\n",
    "                     for search_term in search_terms]\n",
    "    stemmed_title = [' '.join(stemmed(tokenize(t)))\n",
    "                     for t in train_df['product_title']]\n",
    "    stemmed_desc = [' '.join(stemmed(tokenize(d)))\n",
    "                    for d in train_df['product_description']]\n",
    "\n",
    "    train_df['stemmed_terms'] = stemmed_terms\n",
    "    train_df['stemmed_title'] = stemmed_title\n",
    "    train_df['stemmed_desc'] = stemmed_desc\n",
    "\n",
    "    stemmed_terms = list(train_df['stemmed_terms'])\n",
    "    stemmed_title = list(train_df['stemmed_title'])\n",
    "    stemmed_desc = list(train_df['stemmed_desc'])\n",
    "\n",
    "    # lemmatize the search terms, title, and descriptions\n",
    "    lemmatized_terms = [' '.join(lemmatized(tokenize(search_term)))\n",
    "                        for search_term in search_terms]\n",
    "    lemmatized_title = [' '.join(lemmatized(tokenize(t)))\n",
    "                        for t in train_df['product_title']]\n",
    "    lemmatized_desc = [' '.join(lemmatized(tokenize(d)))\n",
    "                       for d in train_df['product_description']]\n",
    "\n",
    "    train_df['lemmatized_terms'] = lemmatized_terms\n",
    "    train_df['lemmatized_title'] = lemmatized_title\n",
    "    train_df['lemmatized_desc'] = lemmatized_desc\n",
    "\n",
    "    lemmatized_terms = list(train_df['lemmatized_terms'])\n",
    "    lemmatized_title = list(train_df['lemmatized_title'])\n",
    "    lemmatized_desc = list(train_df['lemmatized_desc'])\n",
    "\n",
    "    # set up the calculations for finding the nearest neighbors\n",
    "    wordlist, matrix = split_dictionary()\n",
    "    cleaned_set = unique_words(train_df)\n",
    "    find_nearest_neighbors('glove_neighbour_no_w.txt',\n",
    "                           cleaned_set, matrix, wordlist, dictionary)\n",
    "    k_dict = build_dictionary('glove_neighbour_no_w.txt')\n",
    "    terms_neighbour = get_all_terms_neighbors(k_dict, cleaned)\n",
    "    train_df['terms_neighbour'] = terms_neighbour\n",
    "\n",
    "    # create the features to be used in the model\n",
    "    train_df['clean_length'] = get_length(cleaned)\n",
    "    train_df['title_length'] = get_length(title)\n",
    "    train_df['desc_length'] = get_length(desc)\n",
    "    train_df['clean_terms_in_title'] = clean_term_in_doc(cleaned, title)\n",
    "    train_df['clean_terms_in_desc'] = clean_term_in_doc(cleaned, desc)\n",
    "    train_df['stemmed_terms_in_title'] = clean_term_in_doc(\n",
    "        stemmed_terms, stemmed_title)\n",
    "    train_df['stemmed_terms_in_desc'] = clean_term_in_doc(\n",
    "        stemmed_terms, stemmed_desc)\n",
    "    train_df['lemmatized_terms_in_title'] = clean_term_in_doc(\n",
    "        lemmatized_terms, lemmatized_title)\n",
    "    train_df['lemmatized_terms_in_desc'] = clean_term_in_doc(\n",
    "        lemmatized_terms, lemmatized_desc)\n",
    "    train_df['neighbours_in_title'] = clean_term_in_doc(terms_neighbour, title)\n",
    "    train_df['neighbours_in_desc'] = clean_term_in_doc(terms_neighbour, desc)\n",
    "\n",
    "    train_df['search_terms_entropy'] = calculate_entropy(letter_prob(cleaned))\n",
    "    train_df['title_entropy'] = calculate_entropy(letter_prob(title))\n",
    "    train_df['jaccard_index_title'] = calculate_jaccard_index(title, cleaned)\n",
    "    train_df['jaccard_index_desc'] = calculate_jaccard_index(desc, cleaned)\n",
    "    train_df['lcs_title'] = longest_common_subsequence(cleaned, title)\n",
    "    train_df['lcs_desc'] = longest_common_subsequence(cleaned, desc)\n",
    "\n",
    "    return train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-06T18:37:23.834926Z",
     "start_time": "2018-12-06T18:37:22.519411Z"
    }
   },
   "outputs": [],
   "source": [
    "products = pd.read_csv('product_descriptions.csv')\n",
    "train = pd.read_csv('train.csv', encoding='ISO-8859-1')\n",
    "attributes = pd.read_csv('attributes.csv', encoding='ISO-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-06T18:39:59.137643Z",
     "start_time": "2018-12-06T18:37:23.837043Z"
    }
   },
   "outputs": [],
   "source": [
    "# BEWARE: this takes ~2.5 min to run\n",
    "attrib_per_product = attrib_stack(attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-03T02:06:10.426388Z",
     "start_time": "2018-12-03T02:06:00.678100Z"
    }
   },
   "outputs": [],
   "source": [
    "train, attrib_per_product = join_attrib(train, attrib_per_product)\n",
    "train = search_term_in_attrib(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-03T02:09:50.929656Z",
     "start_time": "2018-12-03T02:06:10.429741Z"
    }
   },
   "outputs": [],
   "source": [
    "# BEWARE: this takes ~4 min to run\n",
    "train = color_df(attributes, train)\n",
    "train = search_title_lev_dist(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-03T02:10:16.436329Z",
     "start_time": "2018-12-03T02:09:50.932026Z"
    }
   },
   "outputs": [],
   "source": [
    "train = search_brand_lev_dist(train, attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-03T02:10:16.472181Z",
     "start_time": "2018-12-03T02:10:16.438230Z"
    }
   },
   "outputs": [],
   "source": [
    "train_temp = train.drop(['id', 'name', 'value', 'search_term_split',\n",
    "                         'color', 'product_title_clean', 'brand'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-03T02:10:44.341514Z",
     "start_time": "2018-12-03T02:10:16.474006Z"
    }
   },
   "outputs": [],
   "source": [
    "glove_file = 'glove.6B.300d.txt'\n",
    "glove_dic = make_dictionary(glove_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-03T03:13:39.992282Z",
     "start_time": "2018-12-03T02:47:25.832054Z"
    }
   },
   "outputs": [],
   "source": [
    "# BEWARE: this takes ~26 min to run\n",
    "modified_train = feature_engineering(train, products, glove_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-03T03:17:37.090378Z",
     "start_time": "2018-12-03T03:13:39.995156Z"
    }
   },
   "outputs": [],
   "source": [
    "# BEWARE: this takes ~4 min to run\n",
    "createJaroCol(modified_train, \"search_term\",\n",
    "              \"product_description\", \"jscore_query_desc\")\n",
    "createJaroCol(modified_train, \"search_term\",\n",
    "              \"product_title\", \"jscore_query_title\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-03T03:26:51.403197Z",
     "start_time": "2018-12-03T03:18:22.180241Z"
    }
   },
   "outputs": [],
   "source": [
    "# BEWARE: this takes ~8.5 min to run\n",
    "modified_train = createSWscoreCol(\n",
    "    modified_train, \"search_term\", \"product_title\", \"search_title_SW\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-03T06:48:10.003865Z",
     "start_time": "2018-12-03T05:01:45.404779Z"
    }
   },
   "outputs": [],
   "source": [
    "# BEWARE: this takes ~1hr 46m to run\n",
    "modified_train = createSWscoreCol(\n",
    "    modified_train, \"search_term\", \"product_description\", \"search_desc_SW\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-03T23:45:54.952981Z",
     "start_time": "2018-12-03T09:11:00.024141Z"
    }
   },
   "outputs": [],
   "source": [
    "# BEWARE: this takes ~14hr 35m to run\n",
    "modified_train = createNCDCol(\n",
    "    modified_train, \"search_term\", \"product_title\", \"NCD_query_title\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-05T05:16:29.983429Z",
     "start_time": "2018-12-05T05:16:29.638204Z"
    }
   },
   "outputs": [],
   "source": [
    "modified_train = add_prod_description_column(modified_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-05T05:20:50.926132Z",
     "start_time": "2018-12-05T05:20:14.780600Z"
    }
   },
   "outputs": [],
   "source": [
    "modified_train = add_word_count_features(modified_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-05T05:36:18.780820Z",
     "start_time": "2018-12-05T05:33:29.598989Z"
    }
   },
   "outputs": [],
   "source": [
    "# BEWARE: this takes ~3m to run\n",
    "modified_train = add_num_attrib_per_prod_column(modified_train, attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-05T10:52:24.685042Z",
     "start_time": "2018-12-05T05:40:13.048095Z"
    }
   },
   "outputs": [],
   "source": [
    "# BEWARE, this takes ~5h 12m to run\n",
    "modified_train = find_n_tfidf_highest_scores(modified_train, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-05T13:46:33.455394Z",
     "start_time": "2018-12-05T13:46:24.648962Z"
    }
   },
   "outputs": [],
   "source": [
    "modified_train = find_tfidf_words_in_search(modified_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-05T14:09:28.009102Z",
     "start_time": "2018-12-05T14:09:27.707879Z"
    }
   },
   "outputs": [],
   "source": [
    "modified_train = add_tfidf_col(modified_train)\n",
    "modified_train['num_attrib'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-05T14:41:01.088701Z",
     "start_time": "2018-12-05T14:41:01.052069Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['product_uid' 'id' 'product_title' 'search_term' 'relevance' 'name'\n",
      " 'value' 'search_term_split' 'search_term_in_attrib' 'color'\n",
      " 'color_in_search_term' 'product_title_clean' 'min_levenstein_dist_title'\n",
      " 'brand' 'min_levenstein_dist_brand' 'product_description' 'cleaned_terms'\n",
      " 'stemmed_terms' 'stemmed_title' 'stemmed_desc' 'lemmatized_terms'\n",
      " 'lemmatized_title' 'lemmatized_desc' 'terms_neighbour' 'clean_length'\n",
      " 'title_length' 'desc_length' 'clean_terms_in_title' 'clean_terms_in_desc'\n",
      " 'stemmed_terms_in_title' 'stemmed_terms_in_desc'\n",
      " 'lemmatized_terms_in_title' 'lemmatized_terms_in_desc'\n",
      " 'neighbours_in_title' 'neighbours_in_desc' 'search_terms_entropy'\n",
      " 'title_entropy' 'jaccard_index_title' 'jaccard_index_desc' 'lcs_title'\n",
      " 'lcs_desc' 'jscore_query_desc' 'jscore_query_title' 'search_title_SW'\n",
      " 'search_desc_SW' 'NCD_query_title' 'total_description'\n",
      " 'num_words_in_description' 'num_stop_words' 'num_search_words'\n",
      " 'num_attrib' 'tfidf' 'tfidf_search_common']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_uid</th>\n",
       "      <th>id</th>\n",
       "      <th>product_title</th>\n",
       "      <th>search_term</th>\n",
       "      <th>relevance</th>\n",
       "      <th>name</th>\n",
       "      <th>value</th>\n",
       "      <th>search_term_split</th>\n",
       "      <th>search_term_in_attrib</th>\n",
       "      <th>color</th>\n",
       "      <th>...</th>\n",
       "      <th>search_title_SW</th>\n",
       "      <th>search_desc_SW</th>\n",
       "      <th>NCD_query_title</th>\n",
       "      <th>total_description</th>\n",
       "      <th>num_words_in_description</th>\n",
       "      <th>num_stop_words</th>\n",
       "      <th>num_search_words</th>\n",
       "      <th>num_attrib</th>\n",
       "      <th>tfidf</th>\n",
       "      <th>tfidf_search_common</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100001</td>\n",
       "      <td>2</td>\n",
       "      <td>Simpson Strong-Tie 12-Gauge Angle</td>\n",
       "      <td>angle bracket</td>\n",
       "      <td>3.0</td>\n",
       "      <td>['Bullet01', 'Bullet02', 'Bullet03', 'Bullet04...</td>\n",
       "      <td>{'stronger', 'consist', 'extra', 'instal', 'jo...</td>\n",
       "      <td>[angl, bracket]</td>\n",
       "      <td>1</td>\n",
       "      <td>{''}</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.107077</td>\n",
       "      <td>Simpson Strong-Tie 12-Gauge AngleNot only do a...</td>\n",
       "      <td>79</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>15.0</td>\n",
       "      <td>[angl, simpson, strong, tie, project]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100001</td>\n",
       "      <td>3</td>\n",
       "      <td>Simpson Strong-Tie 12-Gauge Angle</td>\n",
       "      <td>l bracket</td>\n",
       "      <td>2.5</td>\n",
       "      <td>['Bullet01', 'Bullet02', 'Bullet03', 'Bullet04...</td>\n",
       "      <td>{'stronger', 'consist', 'extra', 'instal', 'jo...</td>\n",
       "      <td>[bracket]</td>\n",
       "      <td>0</td>\n",
       "      <td>{''}</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.107077</td>\n",
       "      <td>Simpson Strong-Tie 12-Gauge AngleNot only do a...</td>\n",
       "      <td>79</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>15.0</td>\n",
       "      <td>[angl, simpson, strong, tie, project]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100002</td>\n",
       "      <td>9</td>\n",
       "      <td>BEHR Premium Textured DeckOver 1-gal. #SC-141 ...</td>\n",
       "      <td>deck over</td>\n",
       "      <td>3.0</td>\n",
       "      <td>['Application Method', 'Assembled Depth (in.)'...</td>\n",
       "      <td>{'represent', 'durabl', 'behr', 'slip', 'follo...</td>\n",
       "      <td>[deck]</td>\n",
       "      <td>1</td>\n",
       "      <td>{'Tans', 'Browns', 'Tugboat'}</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.109091</td>\n",
       "      <td>BEHR Premium Textured DeckOver 1-gal. #SC-141 ...</td>\n",
       "      <td>109</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>35.0</td>\n",
       "      <td>[concret, deckov, behr, textur, deck]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 53 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   product_uid  id                                      product_title  \\\n",
       "0       100001   2                  Simpson Strong-Tie 12-Gauge Angle   \n",
       "1       100001   3                  Simpson Strong-Tie 12-Gauge Angle   \n",
       "2       100002   9  BEHR Premium Textured DeckOver 1-gal. #SC-141 ...   \n",
       "\n",
       "     search_term  relevance  \\\n",
       "0  angle bracket        3.0   \n",
       "1      l bracket        2.5   \n",
       "2      deck over        3.0   \n",
       "\n",
       "                                                name  \\\n",
       "0  ['Bullet01', 'Bullet02', 'Bullet03', 'Bullet04...   \n",
       "1  ['Bullet01', 'Bullet02', 'Bullet03', 'Bullet04...   \n",
       "2  ['Application Method', 'Assembled Depth (in.)'...   \n",
       "\n",
       "                                               value search_term_split  \\\n",
       "0  {'stronger', 'consist', 'extra', 'instal', 'jo...   [angl, bracket]   \n",
       "1  {'stronger', 'consist', 'extra', 'instal', 'jo...         [bracket]   \n",
       "2  {'represent', 'durabl', 'behr', 'slip', 'follo...            [deck]   \n",
       "\n",
       "   search_term_in_attrib                          color         ...          \\\n",
       "0                      1                           {''}         ...           \n",
       "1                      0                           {''}         ...           \n",
       "2                      1  {'Tans', 'Browns', 'Tugboat'}         ...           \n",
       "\n",
       "   search_title_SW search_desc_SW  NCD_query_title  \\\n",
       "0              1.0            4.0         0.107077   \n",
       "1              0.0            0.0         0.107077   \n",
       "2              0.0            3.0         0.109091   \n",
       "\n",
       "                                   total_description  \\\n",
       "0  Simpson Strong-Tie 12-Gauge AngleNot only do a...   \n",
       "1  Simpson Strong-Tie 12-Gauge AngleNot only do a...   \n",
       "2  BEHR Premium Textured DeckOver 1-gal. #SC-141 ...   \n",
       "\n",
       "   num_words_in_description num_stop_words num_search_words num_attrib  \\\n",
       "0                        79              0                2       15.0   \n",
       "1                        79              0                2       15.0   \n",
       "2                       109              1                2       35.0   \n",
       "\n",
       "                                   tfidf tfidf_search_common  \n",
       "0  [angl, simpson, strong, tie, project]                   0  \n",
       "1  [angl, simpson, strong, tie, project]                   0  \n",
       "2  [concret, deckov, behr, textur, deck]                   0  \n",
       "\n",
       "[3 rows x 53 columns]"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(modified_train.columns.values)\n",
    "modified_train[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Becaues of the time-consuming nature of the feature engineering, we saved the data into a csv. If you don't want to run all of the previous functions (which takes over 16 hours to run), just start with the cells below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-07T01:10:37.877716Z",
     "start_time": "2018-12-07T01:10:32.745008Z"
    }
   },
   "outputs": [],
   "source": [
    "zip_data = zipfile.ZipFile('final_dataset.csv.zip')\n",
    "zip_data.extractall()\n",
    "modified_train = pd.read_csv('final_dataset.csv')\n",
    "modified_train = modified_train.drop('Unnamed: 0', axis=1)\n",
    "assert(len(modified_train.columns) == 49)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-07T01:10:37.897502Z",
     "start_time": "2018-12-07T01:10:37.879729Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train = modified_train[['clean_length', 'title_length',\n",
    "                          'desc_length', 'clean_terms_in_title',\n",
    "                          'clean_terms_in_desc', 'stemmed_terms_in_title',\n",
    "                          'stemmed_terms_in_desc', 'lemmatized_terms_in_title',\n",
    "                          'lemmatized_terms_in_desc', 'neighbours_in_title',\n",
    "                          'neighbours_in_desc',\n",
    "                          'min_levenstein_dist_title', 'min_levenstein_dist_brand',\n",
    "                          'stemmed_terms_in_title', 'stemmed_terms_in_desc',\n",
    "                          'lemmatized_terms_in_title', 'lemmatized_terms_in_desc',\n",
    "                          'neighbours_in_title', 'neighbours_in_desc', 'search_terms_entropy',\n",
    "                          'title_entropy', 'jaccard_index_title', 'jaccard_index_desc', 'lcs_title',\n",
    "                          'lcs_desc', 'jscore_query_desc', 'jscore_query_title', 'search_title_SW',\n",
    "                          'search_desc_SW', 'NCD_query_title', 'num_words_in_description', 'num_stop_words',\n",
    "                          'num_search_words', 'tfidf_search_common', 'num_attrib']]\n",
    "y_train = modified_train[['relevance']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we can't see the relevancy scores of the test set, we decided to split the training set further into our own training and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-07T01:10:37.931651Z",
     "start_time": "2018-12-07T01:10:37.899505Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data, test_data, train_target, test_target = train_test_split(X_train,\n",
    "                                                                    y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-07T01:10:38.673805Z",
     "start_time": "2018-12-07T01:10:38.670676Z"
    }
   },
   "outputs": [],
   "source": [
    "assert(int(math.floor(len(X_train) * .75)) == len(train_data))\n",
    "assert(len(train_data) == len(train_target))\n",
    "assert(int(math.ceil(len(X_train) * .25)) == len(test_data))\n",
    "assert(len(test_data) == len(test_target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a simple baseline, we'll consider the RMSE of a completely random model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-07T02:15:34.369349Z",
     "start_time": "2018-12-07T02:15:34.366134Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74071\n"
     ]
    }
   ],
   "source": [
    "print(len(y_train)) # no empty relevancy score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-07T02:15:42.306267Z",
     "start_time": "2018-12-07T02:15:42.297714Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8746253654706937\n"
     ]
    }
   ],
   "source": [
    "random_score = np.random.uniform(low=1.0, high=3.0, size=len(y_train))\n",
    "random_chance_performance = math.sqrt(mean_squared_error(random_score, y_train))\n",
    "print(random_chance_performance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Fitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our simplest model, we decided to use linear regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-07T01:10:41.719231Z",
     "start_time": "2018-12-07T01:10:41.637787Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_reg_model = LinearRegression()\n",
    "lin_reg_model.fit(train_data, train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-07T01:10:42.455264Z",
     "start_time": "2018-12-07T01:10:42.444816Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.222388  ]\n",
      " [2.05996623]\n",
      " [2.29824388]\n",
      " [2.32938087]\n",
      " [2.42778731]]\n",
      "       relevance\n",
      "6436        1.67\n",
      "52863       1.67\n",
      "63768       1.67\n",
      "50948       2.67\n",
      "30097       3.00\n"
     ]
    }
   ],
   "source": [
    "predicted = lin_reg_model.predict(test_data)\n",
    "print(predicted[:5])\n",
    "print(test_target[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After some exploration, we realized that some of the predictions produced by linear regression exceeded the bounds of the relevancy score metric. To account for that, we performed a min-max scaling to get the predictions within the bounds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-07T01:10:47.354443Z",
     "start_time": "2018-12-07T01:10:47.348132Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.15978968]\n",
      " [2.01318068]\n",
      " [2.22826052]\n",
      " [2.25636613]\n",
      " [2.3451921 ]]\n",
      "       relevance\n",
      "6436        1.67\n",
      "52863       1.67\n",
      "63768       1.67\n",
      "50948       2.67\n",
      "30097       3.00\n"
     ]
    }
   ],
   "source": [
    "scaler = MinMaxScaler(feature_range=(1.0, 3.0))\n",
    "scaled_linear_predicted = scaler.fit_transform(predicted)\n",
    "print(scaled_linear_predicted[:5])\n",
    "print(test_target[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For good measure, we considered alternative linear models that have regularization like Lasso, Ridge and ElasticNet to evaluate if there was overfitting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search_models_rmse(models, model_params, cv_value):\n",
    "    \"\"\"\n",
    "    :param models:          a list of pipelines of models\n",
    "    :param model\n",
    "    \"\"\"\n",
    "    best_models = []\n",
    "    for model in zip(models, model_params):\n",
    "        gs = GridSearchCV(estimator=model[0],\n",
    "                          param_grid=model[1],\n",
    "                          scoring='neg_mean_squared_error',\n",
    "                          cv=cv_value)\n",
    "        if type(y_train) != np.ndarray:\n",
    "            y = y_train.values.ravel()\n",
    "            y_train = np.array(y).astype(float)\n",
    "        gs.fit(X_train, y_train.ravel())\n",
    "        best_models_alt_linear.append(\n",
    "            (sqrt(-1 * gs.best_score_), gs.best_params_, model[0]))\n",
    "    return best_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-06T23:56:34.319725Z",
     "start_time": "2018-12-06T23:45:44.221055Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.5308711292115721, {'alpha': 0.25, 'normalize': False, 'selection': 'random'}, Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
      "   normalize=False, positive=False, precompute=False, random_state=None,\n",
      "   selection='cyclic', tol=0.0001, warm_start=False)), (0.4946356430077207, {'alpha': 0.5, 'normalize': False, 'solver': 'svd'}, Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
      "   normalize=False, random_state=None, solver='auto', tol=0.001)), (0.5186387637495514, {'alpha': 0.5, 'l1_ratio': 0.25, 'normalize': False, 'selection': 'cyclic'}, ElasticNet(alpha=1.0, copy_X=True, fit_intercept=True, l1_ratio=0.5,\n",
      "      max_iter=1000, normalize=False, positive=False, precompute=False,\n",
      "      random_state=None, selection='cyclic', tol=0.0001, warm_start=False))]\n"
     ]
    }
   ],
   "source": [
    "# BEWARE: this takes ~11m to run\n",
    "alt_linear_models = [Lasso(),\n",
    "                     Ridge(),\n",
    "                     ElasticNet()]\n",
    "\n",
    "alt_linear_grid_params = [{'alpha': np.linspace(start=0.25, stop=1.0, num=4),\n",
    "                           'normalize': [False, True],\n",
    "                           'selection': ['cyclic', 'random']},\n",
    "                          {'alpha': np.linspace(start=0.5, stop=2.0, num=4),\n",
    "                           'normalize': [False, True],\n",
    "                           'solver': ['svd', 'lsqr', 'sag', 'saga']},\n",
    "                          {'alpha': np.linspace(start=0.5, stop=2.0, num=4),\n",
    "                           'l1_ratio': np.linspace(start=0.25, stop=1.0, num=4),\n",
    "                           'normalize': [False, True],\n",
    "                           'selection': ['cyclic', 'random']}]\n",
    "best_models_alt_linear = []\n",
    "for model in zip(alt_linear_models, alt_linear_grid_params):\n",
    "    gs = GridSearchCV(estimator=model[0],\n",
    "                      param_grid=model[1],\n",
    "                      scoring='neg_mean_squared_error',\n",
    "                      cv=5)\n",
    "    if type(y_train) != np.ndarray:\n",
    "        y = y_train.values.ravel()\n",
    "        y_train = np.array(y).astype(float)\n",
    "    gs.fit(X_train, y_train.ravel())\n",
    "    best_models_alt_linear.append(\n",
    "        (sqrt(-1 * gs.best_score_), gs.best_params_, model[0]))\n",
    "\n",
    "print(best_models_alt_linear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-06T23:56:34.419975Z",
     "start_time": "2018-12-06T23:56:34.322587Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.10183055]\n",
      " [2.18559358]\n",
      " [2.12364928]\n",
      " [2.50951735]\n",
      " [2.57230042]]\n",
      "       relevance\n",
      "49710       2.67\n",
      "58951       1.33\n",
      "45702       2.33\n",
      "63338       2.00\n",
      "71218       2.00\n"
     ]
    }
   ],
   "source": [
    "best_model_alt_linear = sorted(\n",
    "    best_models_alt_linear, key=lambda model: model[0])[0]\n",
    "best_model_alt_linear = best_model_alt_linear[2].__class__(\n",
    "    **best_model_alt_linear[1])\n",
    "best_model_alt_linear.fit(train_data, train_target)\n",
    "alt_linear_predicted = best_model_alt_linear.predict(test_data)\n",
    "print(alt_linear_predicted[:5])\n",
    "print(test_target[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tree-based Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After considering various linear models, we decided to test if tree-based models could improve upon the performance of the linear models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-07T00:22:45.884381Z",
     "start_time": "2018-12-06T23:56:34.422530Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.4766320708963225, {'max_features': 'log2', 'n_estimators': 26}, RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
      "           max_features='auto', max_leaf_nodes=None,\n",
      "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "           min_samples_leaf=1, min_samples_split=2,\n",
      "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
      "           oob_score=False, random_state=None, verbose=0, warm_start=False)), (0.5021121390851352, {'learning_rate': 0.75, 'loss': 'linear', 'n_estimators': 6}, AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',\n",
      "         n_estimators=50, random_state=None))]\n"
     ]
    }
   ],
   "source": [
    "# BEWARE: this takes ~26m to run\n",
    "tree_models = [RandomForestRegressor(),\n",
    "               AdaBoostRegressor()]\n",
    "\n",
    "grid_params_tree = [{'n_estimators': range(1, 30, 5),\n",
    "                     'max_features': ['auto', 'sqrt', 'log2', None]},\n",
    "                    {'n_estimators': range(1, 30, 5),\n",
    "                     'loss': ['linear', 'square'],\n",
    "                     'learning_rate': np.linspace(start=0.5, stop=1.5, num=5)}]\n",
    "best_models_tree = []\n",
    "for model in zip(tree_models, grid_params_tree):\n",
    "    gs = GridSearchCV(estimator=model[0],\n",
    "                      param_grid=model[1],\n",
    "                      scoring='neg_mean_squared_error',\n",
    "                      cv=5)\n",
    "    if type(y_train) != np.ndarray:\n",
    "        y = y_train.values.ravel()\n",
    "        y_train = np.array(y).astype(float)\n",
    "    gs.fit(X_train, y_train.ravel())\n",
    "    best_models_tree.append(\n",
    "        (sqrt(-1 * gs.best_score_), gs.best_params_, model[0]))\n",
    "\n",
    "print(best_models_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-07T00:22:49.406462Z",
     "start_time": "2018-12-07T00:22:45.886499Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/robertsandor/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:4: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.22153846 2.23038462 2.34615385 2.16653846 2.24076923]\n",
      "       relevance\n",
      "49710       2.67\n",
      "58951       1.33\n",
      "45702       2.33\n",
      "63338       2.00\n",
      "71218       2.00\n"
     ]
    }
   ],
   "source": [
    "# here we chose the best tree model\n",
    "best_tree_model = sorted(best_models_tree, key=lambda model: model[0])[0]\n",
    "best_tree_model = best_tree_model[2].__class__(**best_tree_model[1])\n",
    "best_tree_model.fit(train_data, train_target)\n",
    "tree_predicted = best_tree_model.predict(test_data)\n",
    "print(tree_predicted[:5])\n",
    "print(test_target[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-07T00:44:33.545815Z",
     "start_time": "2018-12-07T00:27:21.456556Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.46981443222286356, {'rf_reg__max_features': 'log2', 'rf_reg__n_estimators': 135}, Pipeline(memory=None,\n",
      "     steps=[('rf_reg', RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
      "           max_features='auto', max_leaf_nodes=None,\n",
      "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "           min_samples_leaf=1, min_samples_split=2,\n",
      "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
      "           oob_score=False, random_state=None, verbose=0, warm_start=False))]))]\n"
     ]
    }
   ],
   "source": [
    "# BEWARE : this takes ~17m to run\n",
    "rf_models = [Pipeline([('rf_reg', RandomForestRegressor())])]\n",
    "\n",
    "grid_params_rf = [{'rf_reg__n_estimators': range(25, 151, 10),\n",
    "                   'rf_reg__max_features': ['log2']}]\n",
    "best_models_rf = []\n",
    "for model in zip(rf_models, grid_params_rf):\n",
    "    gs = GridSearchCV(estimator=model[0],\n",
    "                      param_grid=model[1],\n",
    "                      scoring='neg_mean_squared_error',\n",
    "                      cv=5)\n",
    "    if type(y_train) != np.ndarray:\n",
    "        y = y_train.values.ravel()\n",
    "        y_train = np.array(y).astype(float)\n",
    "    gs.fit(X_train, y_train.ravel())\n",
    "    best_models_rf.append(\n",
    "        (sqrt(-1 * gs.best_score_), gs.best_params_, model[0]))\n",
    "\n",
    "print(best_models_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-07T00:51:58.547956Z",
     "start_time": "2018-12-07T00:51:58.541966Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.ensemble.forest.RandomForestRegressor'>\n",
      "{'rf_reg__max_features': 'log2', 'rf_reg__n_estimators': 135}\n",
      "{'max_features': 'log2', 'n_estimators': 135}\n"
     ]
    }
   ],
   "source": [
    "best_rf_model = sorted(best_models_rf, key=lambda model: model[0])[0]\n",
    "best_rf_model[1]['max_features'] = best_rf_model[1].pop('rf_reg__max_features')\n",
    "best_rf_model[1]['n_estimators'] = best_rf_model[1].pop('rf_reg__n_estimators')\n",
    "best_rf_model = (best_rf_model[0], best_rf_model[1], best_rf_model[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-07T00:52:38.092864Z",
     "start_time": "2018-12-07T00:52:19.827396Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/robertsandor/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:4: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.19407407 2.26325926 2.33103704 2.23274074 2.20696296]\n",
      "       relevance\n",
      "49710       2.67\n",
      "58951       1.33\n",
      "45702       2.33\n",
      "63338       2.00\n",
      "71218       2.00\n"
     ]
    }
   ],
   "source": [
    "best_rf_model = best_rf_model[2].steps[0][1].__class__(\n",
    "    **best_rf_model[1])\n",
    "best_rf_model.fit(train_data, train_target)\n",
    "rf_predicted = best_rf_model.predict(test_data)\n",
    "print(rf_predicted[:5])\n",
    "print(test_target[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To be thorough, we also considered a model that used boosting (Gradient Boosting) to see how boosting would compare to all of our models thus far."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-07T01:18:56.589225Z",
     "start_time": "2018-12-07T01:13:07.213631Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.48326051146343524, {'gb_reg__learning_rate': 0.5, 'gb_reg__loss': 'ls', 'gb_reg__n_estimators': 21}, Pipeline(memory=None,\n",
      "     steps=[('gb_reg', GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
      "             learning_rate=0.1, loss='ls', max_depth=3, max_features=None,\n",
      "             max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "             min_impurity_split=None, min_samples_leaf=1,\n",
      "             min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "             n_estimators=100, presort='auto', random_state=None,\n",
      "             subsample=1.0, verbose=0, warm_start=False))]))]\n"
     ]
    }
   ],
   "source": [
    "# BEWARE: this takes ~14m to run\n",
    "gb_model_pipeline = [Pipeline([('gb_reg', GradientBoostingRegressor())])]\n",
    "\n",
    "grid_params_gb = [{'gb_reg__loss': ['ls', 'huber'],\n",
    "                   'gb_reg__n_estimators': range(1, 26, 5),\n",
    "                   'gb_reg__learning_rate': [0.1, 0.25, 0.5, 0.75, 0.9]}]\n",
    "best_gb_models = []\n",
    "for model in zip(gb_model_pipeline, grid_params_gb):\n",
    "    gs = GridSearchCV(estimator=model[0],\n",
    "                      param_grid=model[1],\n",
    "                      scoring='neg_mean_squared_error',\n",
    "                      cv=5)\n",
    "    if type(y_train) != np.ndarray:\n",
    "        y = y_train.values.ravel()\n",
    "        y_train = np.array(y).astype(float)\n",
    "    gs.fit(X_train, y_train.ravel())\n",
    "    best_gb_models.append(\n",
    "        (sqrt(-1 * gs.best_score_), gs.best_params_, model[0]))\n",
    "\n",
    "print(best_gb_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-07T01:18:56.599459Z",
     "start_time": "2018-12-07T01:18:56.592765Z"
    }
   },
   "outputs": [],
   "source": [
    "best_gb_model = sorted(\n",
    "    best_gb_models, key=lambda model: model[0])[0]\n",
    "best_gb_model[1]['learning_rate'] = best_gb_model[1].pop(\n",
    "    'gb_reg__learning_rate')\n",
    "best_gb_model[1]['n_estimators'] = best_gb_model[1].pop(\n",
    "    'gb_reg__n_estimators')\n",
    "best_gb_model[1]['loss'] = best_gb_model[1].pop(\n",
    "    'gb_reg__loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-07T01:18:58.829860Z",
     "start_time": "2018-12-07T01:18:56.603726Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/robertsandor/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.2805891  2.00586902 2.33699338 2.18935758 2.3945759 ]\n",
      "       relevance\n",
      "6436        1.67\n",
      "52863       1.67\n",
      "63768       1.67\n",
      "50948       2.67\n",
      "30097       3.00\n"
     ]
    }
   ],
   "source": [
    "best_gb_model = best_gb_model[2].steps[0][1].__class__(\n",
    "    **best_gb_model[1])\n",
    "\n",
    "best_gb_model.fit(train_data, train_target)\n",
    "gb_predicted = best_gb_model.predict(test_data)\n",
    "print(gb_predicted[:5])\n",
    "print(test_target[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tree-Based Models - Reduced Dimensionality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After evaluating performance on Random Forest models, we wondered how applying PCA (Principal Component Analysis) to reduce the dimensionality of our data would affect performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-07T01:06:02.871886Z",
     "start_time": "2018-12-07T00:59:48.531923Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.469774117760618, {'rf_reg__max_features': 'log2', 'rf_reg__n_estimators': 138}, Pipeline(memory=None,\n",
      "     steps=[('rf_reg', RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
      "           max_features='auto', max_leaf_nodes=None,\n",
      "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "           min_samples_leaf=1, min_samples_split=2,\n",
      "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
      "           oob_score=False, random_state=None, verbose=0, warm_start=False))]))]\n"
     ]
    }
   ],
   "source": [
    "# BEWARE: this takes ~6m to run\n",
    "transformed_rf_models = [Pipeline([('scale', StandardScaler()),\n",
    "                                   ('pca', PCA(n_components=int(\n",
    "                                       math.log2(len(X_train.columns))))),\n",
    "                                   ('rf_reg', RandomForestRegressor())])]\n",
    "\n",
    "grid_params_transformed_rf = [{'rf_reg__n_estimators': range(138, 143, 2),\n",
    "                               'rf_reg__max_features': ['log2']}]\n",
    "\n",
    "best_models_transformed_rf = []\n",
    "for model in zip(rf_models, grid_params_transformed_rf):\n",
    "    gs = GridSearchCV(estimator=model[0],\n",
    "                      param_grid=model[1],\n",
    "                      scoring='neg_mean_squared_error',\n",
    "                      cv=5)\n",
    "    if type(y_train) != np.ndarray:\n",
    "        y = y_train.values.ravel()\n",
    "        y_train = np.array(y).astype(float)\n",
    "    gs.fit(X_train, y_train.ravel())\n",
    "    best_models_transformed_rf.append(\n",
    "        (sqrt(-1 * gs.best_score_), gs.best_params_, model[0]))\n",
    "\n",
    "print(best_models_transformed_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-07T01:07:41.014235Z",
     "start_time": "2018-12-07T01:07:41.010632Z"
    }
   },
   "outputs": [],
   "source": [
    "best_transformed_rf_model = sorted(\n",
    "    best_models_transformed_rf, key=lambda model: model[0])[0]\n",
    "best_transformed_rf_model[1]['max_features'] = best_transformed_rf_model[1].pop(\n",
    "    'rf_reg__max_features')\n",
    "best_transformed_rf_model[1]['n_estimators'] = best_transformed_rf_model[1].pop(\n",
    "    'rf_reg__n_estimators')\n",
    "best_transformed_rf_model = (\n",
    "    best_transformed_rf_model[0], best_transformed_rf_model[1], best_transformed_rf_model[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-07T01:09:15.911016Z",
     "start_time": "2018-12-07T01:08:55.988935Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/robertsandor/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:5: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.23543478 2.20797101 2.29949275 2.23333333 2.16615942]\n",
      "       relevance\n",
      "49710       2.67\n",
      "58951       1.33\n",
      "45702       2.33\n",
      "63338       2.00\n",
      "71218       2.00\n"
     ]
    }
   ],
   "source": [
    "best_transformed_rf_model = sorted(\n",
    "    best_models_transformed_rf, key=lambda model: model[0])[0]\n",
    "best_transformed_rf_model = best_transformed_rf_model[2].steps[0][1].__class__(\n",
    "    **best_transformed_rf_model[1])\n",
    "best_transformed_rf_model.fit(train_data, train_target)\n",
    "transformed_rf_predicted = best_transformed_rf_model.predict(test_data)\n",
    "print(transformed_rf_predicted[:5])\n",
    "print(test_target[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Smaller Feature Space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We decided to also test out how using only certain 'categories' of our features would affect our model. We grouped our model into similarity features (Jaro index, Jaccard index, etc.),  count features, and length/entropy features. \n",
    "\n",
    "We then tested out the best models using only those subsets of features to compare to the performance of the model with the full set of features. This is different than simply using PCA or other dimensionality reduction techniques because PCA may choose a few select features from each of the categories whereas this tests only features from one particular category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-07T01:20:34.614384Z",
     "start_time": "2018-12-07T01:20:34.584696Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stemmed_terms</th>\n",
       "      <th>clean_terms_in_title</th>\n",
       "      <th>clean_terms_in_desc</th>\n",
       "      <th>stemmed_terms_in_title</th>\n",
       "      <th>stemmed_terms_in_desc</th>\n",
       "      <th>lemmatized_terms_in_title</th>\n",
       "      <th>lemmatized_terms_in_desc</th>\n",
       "      <th>neighbours_in_title</th>\n",
       "      <th>neighbours_in_desc</th>\n",
       "      <th>search_terms_entropy</th>\n",
       "      <th>...</th>\n",
       "      <th>jscore_query_desc</th>\n",
       "      <th>jscore_query_title</th>\n",
       "      <th>search_title_SW</th>\n",
       "      <th>search_desc_SW</th>\n",
       "      <th>NCD_query_title</th>\n",
       "      <th>num_words_in_description</th>\n",
       "      <th>num_stop_words</th>\n",
       "      <th>num_search_words</th>\n",
       "      <th>tfidf_search_common</th>\n",
       "      <th>num_attrib</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>angl bracket</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.251629</td>\n",
       "      <td>...</td>\n",
       "      <td>2.833333</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.107077</td>\n",
       "      <td>79</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bracket</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.807355</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.107077</td>\n",
       "      <td>79</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>deck</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.711111</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.109091</td>\n",
       "      <td>109</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  stemmed_terms  clean_terms_in_title  clean_terms_in_desc  \\\n",
       "0  angl bracket                   1.0                  0.0   \n",
       "1       bracket                   0.0                  0.0   \n",
       "2          deck                   0.0                  0.0   \n",
       "\n",
       "   stemmed_terms_in_title  stemmed_terms_in_desc  lemmatized_terms_in_title  \\\n",
       "0                     1.0                    1.0                        1.0   \n",
       "1                     0.0                    0.0                        0.0   \n",
       "2                     0.0                    1.0                        0.0   \n",
       "\n",
       "   lemmatized_terms_in_desc  neighbours_in_title  neighbours_in_desc  \\\n",
       "0                       1.0                  0.0                 1.0   \n",
       "1                       0.0                  0.0                 0.0   \n",
       "2                       1.0                  0.0                 1.0   \n",
       "\n",
       "   search_terms_entropy     ...      jscore_query_desc  jscore_query_title  \\\n",
       "0              3.251629     ...               2.833333            0.866667   \n",
       "1              2.807355     ...               0.000000            0.000000   \n",
       "2              2.000000     ...               2.711111            0.000000   \n",
       "\n",
       "   search_title_SW  search_desc_SW  NCD_query_title  num_words_in_description  \\\n",
       "0              1.0             4.0         0.107077                        79   \n",
       "1              0.0             0.0         0.107077                        79   \n",
       "2              0.0             3.0         0.109091                       109   \n",
       "\n",
       "   num_stop_words  num_search_words  tfidf_search_common  num_attrib  \n",
       "0               0                 2                    1        15.0  \n",
       "1               0                 2                    0        15.0  \n",
       "2               1                 2                    1        35.0  \n",
       "\n",
       "[3 rows x 25 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_num_features = modified_train[getAllNumericalCols(modified_train)]\n",
    "all_num_features.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-07T01:27:13.476326Z",
     "start_time": "2018-12-07T01:27:13.459979Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>neighbours_in_title</th>\n",
       "      <th>neighbours_in_desc</th>\n",
       "      <th>jaccard_index_title</th>\n",
       "      <th>jaccard_index_desc</th>\n",
       "      <th>lcs_title</th>\n",
       "      <th>lcs_desc</th>\n",
       "      <th>jscore_query_desc</th>\n",
       "      <th>jscore_query_title</th>\n",
       "      <th>search_title_SW</th>\n",
       "      <th>search_desc_SW</th>\n",
       "      <th>NCD_query_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>13</td>\n",
       "      <td>2.833333</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.107077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.107077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.012048</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2.711111</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.109091</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   neighbours_in_title  neighbours_in_desc  jaccard_index_title  \\\n",
       "0                  0.0                 1.0             0.166667   \n",
       "1                  0.0                 0.0             0.000000   \n",
       "2                  0.0                 1.0             0.000000   \n",
       "\n",
       "   jaccard_index_desc  lcs_title  lcs_desc  jscore_query_desc  \\\n",
       "0            0.000000          6        13           2.833333   \n",
       "1            0.000000          3         7           0.000000   \n",
       "2            0.012048          4         4           2.711111   \n",
       "\n",
       "   jscore_query_title  search_title_SW  search_desc_SW  NCD_query_title  \n",
       "0            0.866667              1.0             4.0         0.107077  \n",
       "1            0.000000              0.0             0.0         0.107077  \n",
       "2            0.000000              0.0             3.0         0.109091  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_similarity_features = modified_train[getSimilarityCols(all_num_features)]\n",
    "all_similarity_features.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-07T01:27:16.782699Z",
     "start_time": "2018-12-07T01:27:16.775996Z"
    }
   },
   "outputs": [],
   "source": [
    "count_cols, len_h_cols = getCountAndOtherCols(\n",
    "    all_similarity_features, all_num_features)\n",
    "all_count_features = modified_train[count_cols]\n",
    "len_entropy_features = modified_train[len_h_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-07T01:27:18.416454Z",
     "start_time": "2018-12-07T01:27:18.387952Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data_numerical_subset, test_data_numerical_subset, train_target_numerical_subset, test_target_numerical_subset = train_test_split(all_num_features,\n",
    "                                                                                                                                        y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-06T03:41:41.205114Z",
     "start_time": "2018-12-06T03:41:23.099091Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/robertsandor/anaconda3/envs/ml/lib/python3.6/site-packages/ipykernel_launcher.py:1: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.24535714 2.49071429 2.64038095 2.60203571 2.58490476]\n",
      "       relevance\n",
      "64115       2.33\n",
      "55409       2.33\n",
      "57088       2.00\n",
      "38621       3.00\n",
      "50452       2.33\n"
     ]
    }
   ],
   "source": [
    "best_transformed_rf_model.fit(\n",
    "    train_data_numerical_subset, train_target_numerical_subset)\n",
    "transformed_rf_predicted_numerical_subset = best_transformed_rf_model.predict(\n",
    "    test_data_numerical_subset)\n",
    "print(transformed_rf_predicted_numerical_subset[:5])\n",
    "print(test_target[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-06T03:50:20.686019Z",
     "start_time": "2018-12-06T03:50:03.047809Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/robertsandor/anaconda3/envs/ml/lib/python3.6/site-packages/ipykernel_launcher.py:1: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.22330935 2.45896043 2.65258993 2.58966427 2.46791367]\n",
      "       relevance\n",
      "64115       2.33\n",
      "55409       2.33\n",
      "57088       2.00\n",
      "38621       3.00\n",
      "50452       2.33\n"
     ]
    }
   ],
   "source": [
    "best_rf_model.fit(train_data_numerical_subset, train_target_numerical_subset)\n",
    "rf_predicted_numerical_subset = best_rf_model.predict(\n",
    "    test_data_numerical_subset)\n",
    "print(rf_predicted_numerical_subset[:5])\n",
    "print(test_target[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-06T03:41:41.241209Z",
     "start_time": "2018-12-06T03:41:41.208502Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data_similarity_subset, test_data_similarity_subset, train_target_similarity_subset, test_target_similarity_subset = train_test_split(all_similarity_features,\n",
    "                                                                                                                                            y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-06T03:41:56.375934Z",
     "start_time": "2018-12-06T03:41:41.244455Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/robertsandor/anaconda3/envs/ml/lib/python3.6/site-packages/ipykernel_launcher.py:1: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.11857143 2.27058673 2.1015     2.44828571 2.39452381]\n",
      "       relevance\n",
      "64115       2.33\n",
      "55409       2.33\n",
      "57088       2.00\n",
      "38621       3.00\n",
      "50452       2.33\n"
     ]
    }
   ],
   "source": [
    "best_transformed_rf_model.fit(\n",
    "    train_data_similarity_subset, train_target_similarity_subset)\n",
    "transformed_rf_predicted_similarity_subset = best_transformed_rf_model.predict(\n",
    "    test_data_similarity_subset)\n",
    "print(transformed_rf_predicted_similarity_subset[:5])\n",
    "print(test_target[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-06T03:54:14.717152Z",
     "start_time": "2018-12-06T03:53:59.542835Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/robertsandor/anaconda3/envs/ml/lib/python3.6/site-packages/ipykernel_launcher.py:1: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.02188849 2.34651079 2.10170264 2.58411871 2.42079137]\n",
      "       relevance\n",
      "64115       2.33\n",
      "55409       2.33\n",
      "57088       2.00\n",
      "38621       3.00\n",
      "50452       2.33\n"
     ]
    }
   ],
   "source": [
    "best_rf_model.fit(train_data_similarity_subset, train_target_similarity_subset)\n",
    "rf_predicted_similarity_subset = best_rf_model.predict(\n",
    "    test_data_similarity_subset)\n",
    "print(rf_predicted_similarity_subset[:5])\n",
    "print(test_target[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-06T03:59:35.877474Z",
     "start_time": "2018-12-06T03:59:35.856394Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data_count_subset, test_data_count_subset, train_target_count_subset, test_target_count_subset = train_test_split(all_count_features,\n",
    "                                                                                                                        y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-06T03:59:44.036371Z",
     "start_time": "2018-12-06T03:59:36.490203Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/robertsandor/anaconda3/envs/ml/lib/python3.6/site-packages/ipykernel_launcher.py:1: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.62299464 2.61285714 2.37335278 2.22497168 2.24638285]\n",
      "       relevance\n",
      "64115       2.33\n",
      "55409       2.33\n",
      "57088       2.00\n",
      "38621       3.00\n",
      "50452       2.33\n"
     ]
    }
   ],
   "source": [
    "best_transformed_rf_model.fit(\n",
    "    train_data_count_subset, train_target_count_subset)\n",
    "transformed_rf_predicted_count_subset = best_transformed_rf_model.predict(\n",
    "    test_data_count_subset)\n",
    "print(transformed_rf_predicted_count_subset[:5])\n",
    "print(test_target[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-06T04:00:34.417299Z",
     "start_time": "2018-12-06T04:00:26.533260Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/robertsandor/anaconda3/envs/ml/lib/python3.6/site-packages/ipykernel_launcher.py:1: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.62617557 2.52879496 2.36541988 2.20950156 2.27060029]\n",
      "       relevance\n",
      "64115       2.33\n",
      "55409       2.33\n",
      "57088       2.00\n",
      "38621       3.00\n",
      "50452       2.33\n"
     ]
    }
   ],
   "source": [
    "best_rf_model.fit(train_data_count_subset, train_target_count_subset)\n",
    "rf_predicted_count_subset = best_rf_model.predict(test_data_count_subset)\n",
    "print(rf_predicted_count_subset[:5])\n",
    "print(test_target[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-06T04:05:03.345733Z",
     "start_time": "2018-12-06T04:05:03.329956Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data_len_entropy_subset, test_data_len_entropy_subset, train_target_len_entropy_subset, test_target_len_entropy_subset = train_test_split(len_entropy_features,\n",
    "                                                                                                                                                y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-06T04:08:03.419036Z",
     "start_time": "2018-12-06T04:07:46.615343Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/robertsandor/anaconda3/envs/ml/lib/python3.6/site-packages/ipykernel_launcher.py:1: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.54094286 2.59914286 2.36814286 2.59955051 2.06421429]\n",
      "       relevance\n",
      "64115       2.33\n",
      "55409       2.33\n",
      "57088       2.00\n",
      "38621       3.00\n",
      "50452       2.33\n"
     ]
    }
   ],
   "source": [
    "best_transformed_rf_model.fit(\n",
    "    train_data_len_entropy_subset, train_target_len_entropy_subset)\n",
    "transformed_rf_predicted_len_entropy_subset = best_transformed_rf_model.predict(\n",
    "    test_data_len_entropy_subset)\n",
    "print(transformed_rf_predicted_len_entropy_subset[:5])\n",
    "print(test_target[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-06T04:08:46.975873Z",
     "start_time": "2018-12-06T04:08:30.610770Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/robertsandor/anaconda3/envs/ml/lib/python3.6/site-packages/ipykernel_launcher.py:1: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.51521223 2.61115108 2.4346283  2.65931655 1.94434053]\n",
      "       relevance\n",
      "64115       2.33\n",
      "55409       2.33\n",
      "57088       2.00\n",
      "38621       3.00\n",
      "50452       2.33\n"
     ]
    }
   ],
   "source": [
    "best_rf_model.fit(train_data_len_entropy_subset,\n",
    "                  train_target_len_entropy_subset)\n",
    "rf_predicted_len_entropy_subset = best_rf_model.predict(\n",
    "    test_data_len_entropy_subset)\n",
    "print(rf_predicted_len_entropy_subset[:5])\n",
    "print(test_target[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The benchmark was ~rank 1681 on the Kaggle leaderboard for this competition with an RMSE of .51049\n",
    "\n",
    "1st place had an RMSE of .43192\n",
    "\n",
    "https://www.kaggle.com/c/home-depot-product-search-relevance/leaderboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-06T21:29:39.719341Z",
     "start_time": "2018-12-06T21:29:39.715471Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4898\n"
     ]
    }
   ],
   "source": [
    "rmse_lin_reg = sqrt(mean_squared_error(predicted, test_target))\n",
    "\n",
    "print(f\"{rmse_lin_reg:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-06T21:29:41.151643Z",
     "start_time": "2018-12-06T21:29:41.147057Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4981\n"
     ]
    }
   ],
   "source": [
    "rmse_lin_reg_scaled = sqrt(mean_squared_error(scaled_linear_predicted, test_target))\n",
    "\n",
    "print(f\"{rmse_lin_reg_scaled:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-06T02:18:17.693335Z",
     "start_time": "2018-12-06T02:18:17.688835Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4758\n"
     ]
    }
   ],
   "source": [
    "rmse_tree = sqrt(mean_squared_error(tree_predicted, test_target))\n",
    "\n",
    "print(f\"{rmse_tree:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-06T02:18:17.700326Z",
     "start_time": "2018-12-06T02:18:17.695475Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4943\n"
     ]
    }
   ],
   "source": [
    "rmse_alt_linear = sqrt(mean_squared_error(alt_linear_predicted, test_target))\n",
    "\n",
    "print(f\"{rmse_alt_linear:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-06T02:18:17.706941Z",
     "start_time": "2018-12-06T02:18:17.702133Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4688\n"
     ]
    }
   ],
   "source": [
    "rmse_rf = sqrt(mean_squared_error(rf_predicted, test_target))\n",
    "\n",
    "print(f\"{rmse_rf:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-06T02:18:17.714979Z",
     "start_time": "2018-12-06T02:18:17.708651Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4683\n"
     ]
    }
   ],
   "source": [
    "rmse_transformed_rf = sqrt(mean_squared_error(\n",
    "    transformed_rf_predicted, test_target))\n",
    "\n",
    "print(f\"{rmse_transformed_rf:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-06T21:29:49.681973Z",
     "start_time": "2018-12-06T21:29:49.677944Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4786\n"
     ]
    }
   ],
   "source": [
    "rmse_gb = sqrt(mean_squared_error(\n",
    "    gb_predicted, test_target))\n",
    "\n",
    "print(f\"{rmse_gb:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reduced Subset RMSE - Random Forest after PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-06T03:02:42.666595Z",
     "start_time": "2018-12-06T03:02:42.662121Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5992\n"
     ]
    }
   ],
   "source": [
    "rmse_transformed_rf_numerical_subset = sqrt(mean_squared_error(\n",
    "    transformed_rf_predicted_numerical_subset, test_target))\n",
    "\n",
    "print(f\"{rmse_transformed_rf_numerical_subset:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-06T03:42:59.364815Z",
     "start_time": "2018-12-06T03:42:59.359594Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5953\n"
     ]
    }
   ],
   "source": [
    "rmse_transformed_rf_predicted_similarity_subset = sqrt(\n",
    "    mean_squared_error(transformed_rf_predicted_similarity_subset, test_target))\n",
    "\n",
    "print(f\"{transformed_rf_predicted_similarity_subset:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-06T04:02:47.758708Z",
     "start_time": "2018-12-06T04:02:47.753709Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6039\n"
     ]
    }
   ],
   "source": [
    "rmse_transformed_rf_count_subset = sqrt(mean_squared_error(\n",
    "    transformed_rf_predicted_count_subset, test_target))\n",
    "\n",
    "print(f\"{rmse_transformed_rf_count_subset:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-06T04:12:32.832888Z",
     "start_time": "2018-12-06T04:12:32.828041Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5788\n"
     ]
    }
   ],
   "source": [
    "rmse_transformed_rf_len_entropy_subset = sqrt(mean_squared_error(\n",
    "    transformed_rf_predicted_len_entropy_subset, test_target))\n",
    "\n",
    "print(f\"{rmse_transformed_rf_len_entropy_subset:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reduced Subset RMSE - Regular Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-06T03:51:04.842927Z",
     "start_time": "2018-12-06T03:51:04.838276Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5988\n"
     ]
    }
   ],
   "source": [
    "rmse_rf_numerical_subset = sqrt(mean_squared_error(\n",
    "    rf_predicted_numerical_subset, test_target))\n",
    "\n",
    "print(f\"{rmse_rf_numerical_subset:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-06T03:54:27.244229Z",
     "start_time": "2018-12-06T03:54:27.237178Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5950\n"
     ]
    }
   ],
   "source": [
    "rmse_rf_similarity_subset = sqrt(mean_squared_error(\n",
    "    rf_predicted_similarity_subset, test_target))\n",
    "\n",
    "print(f\"{rmse_rf_similarity_subset:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-06T04:03:15.490850Z",
     "start_time": "2018-12-06T04:03:15.482726Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6036\n"
     ]
    }
   ],
   "source": [
    "rmse_rf_count_subset = sqrt(mean_squared_error(\n",
    "    rf_predicted_count_subset, test_target))\n",
    "\n",
    "print(f\"{rmse_rf_count_subset:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-06T04:13:20.589394Z",
     "start_time": "2018-12-06T04:13:20.583976Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5786\n"
     ]
    }
   ],
   "source": [
    "rmse_rf_len_entropy_subset = sqrt(mean_squared_error(\n",
    "    rf_predicted_len_entropy_subset, test_target))\n",
    "\n",
    "print(f\"{rmse_rf_len_entropy_subset:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
