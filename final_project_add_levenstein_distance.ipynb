{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "modified_train.to_csv('modified_train.csv')\n",
    "mt = pd.read_csv('modified_train.csv')\n",
    "mt = mt.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "import string\n",
    "from nltk.stem.porter import *\n",
    "from sklearn.feature_extraction import stop_words\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "def tokenize(text):\n",
    "    \"\"\"\n",
    "    Tokenize text and return a non-unique list of tokenized words\n",
    "    found in the text. Normalize to lowercase, strip punctuation,\n",
    "    remove stop words, drop words of length < 3, strip digits.\n",
    "    \"\"\"\n",
    "    stops = list(stop_words.ENGLISH_STOP_WORDS)\n",
    "    text = text.lower()\n",
    "    regex = re.compile('[' + re.escape(string.punctuation) + '0-9\\\\r\\\\t\\\\n]')\n",
    "    nopunct = regex.sub(\" \", text)  # delete stuff but leave at least a space to avoid clumping together\n",
    "    words = nopunct.split(\" \")\n",
    "    words = [w for w in words if (len(w) > 2 and (w not in stops))]  # ignore a, an, to, at, be, ...\n",
    "    # print words\n",
    "    return words\n",
    "\n",
    "\n",
    "def stemwords(words):\n",
    "    \"\"\"\n",
    "    Given a list of tokens/words, return a new list with each word\n",
    "    stemmed using a PorterStemmer.\n",
    "    \"\"\"\n",
    "    stemmer = PorterStemmer()\n",
    "    words = [stemmer.stem(t) for t in words]\n",
    "\n",
    "    return words\n",
    "\n",
    "def tokenizer(text):\n",
    "    return stemwords(tokenize(text))\n",
    "\n",
    "\n",
    "def attrib_stack(attributes):\n",
    "    \"\"\"\n",
    "    Aggregate all the features of a product into a single description\n",
    "    and return a dataframe with product id and description that is tokenized.\n",
    "    \n",
    "    \"\"\"\n",
    "    attributes['value'] = attributes['value'].apply(lambda x: str(x))\n",
    "    attrib_per_product = attributes.groupby('product_uid').agg(lambda x: x.tolist())\n",
    "    attrib_per_product = attrib_per_product.reset_index()\n",
    "    attrib_per_product['value'] = attrib_per_product['value'].apply(lambda x: ','.join(x))\n",
    "    attrib_per_product['value'] = attrib_per_product['value'].apply(lambda x: tokenizer(x))\n",
    "    attrib_per_product['value'] = attrib_per_product['value'].apply(lambda x: ','.join(x))\n",
    "    attrib_per_product.to_csv('attrib_per_product.csv')\n",
    "    attrib_per_product = pd.read_csv('attrib_per_product.csv')\n",
    "    attrib_per_product = attrib_per_product.drop('Unnamed: 0' ,axis = 1)\n",
    "    return attrib_per_product\n",
    "\n",
    "def join_attrib(train, attrib_per_product):\n",
    "    \"\"\"\n",
    "    Join the aggregated attributes to the train dataframe\n",
    "    \"\"\"\n",
    "    train = train.set_index('product_uid').join(attrib_per_product.set_index('product_uid'))\n",
    "    train = train.reset_index()\n",
    "    attrib_per_product = attrib_per_product.reset_index()\n",
    "    return train, attrib_per_product\n",
    "    \n",
    "def search_term_in_attrib(train):\n",
    "    \"\"\"\n",
    "    Convert the search term (stemmed) and attributes description to a set of words\n",
    "    and find the number of common terms between both in the column search_term_in_attrib.\n",
    "    \"\"\"\n",
    "    train['value'].fillna('', inplace = True)\n",
    "    train['value'] = train['value'].apply(lambda x: set(x.split(',')))\n",
    "    train['search_term_split'] = train['search_term'].apply(lambda x: set(tokenizer(x)))\n",
    "    search_term_in_attrib = [] \n",
    "    for i in range(74067):\n",
    "        p = len(train['search_term_split'][i].intersection(train['value'][i]))\n",
    "        search_term_in_attrib.append(p)\n",
    "    train['search_term_in_attrib'] = search_term_in_attrib\n",
    "    return train\n",
    "\n",
    "def color_df(attributes, train):\n",
    "    \"\"\"\n",
    "    Find the attributes for color per product, join it with train data and \n",
    "    check for match in the search term\n",
    "    \n",
    "    \"\"\"\n",
    "    attrib_col = attributes[attributes['name'].apply(lambda x: 'color' in str(x).lower())]\n",
    "    attrib_col = attrib_col.groupby('product_uid').agg(lambda x: x.tolist())\n",
    "    attrib_col = attrib_col.drop('name',axis = 1)\n",
    "    attrib_col = attrib_col.reset_index()\n",
    "    attrib_col = attrib_col.rename(columns={'value': 'color'})\n",
    "    attrib_col['color'] = attrib_col['color'].apply(lambda x: ','.join(x))\n",
    "    attrib_col['color'] = attrib_col['color'].apply(lambda x: ','.join(x.replace('/','').replace(' ',',').split(',')).replace(',,',','))\n",
    "    train = train.set_index('product_uid').join(attrib_col.set_index('product_uid'))\n",
    "    train = train.reset_index()\n",
    "    attrib_col = attrib_col.reset_index()\n",
    "    train['color'].fillna('', inplace = True)\n",
    "    train['search_term'].fillna('', inplace = True)\n",
    "    train['color'] = train['color'].apply(lambda x: set(x.split(',')))\n",
    "    color_in_search_term = [] \n",
    "    for i in range(74067):\n",
    "        p = len(train['color'][i].intersection(train['search_term_split'][i]))\n",
    "        color_in_search_term.append(p)\n",
    "    train['color_in_search_term']= color_in_search_term\n",
    "    \n",
    "    return train\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_title_lev_dist(train):\n",
    "    \"\"\"\n",
    "    Calculate Levenshtein distance between search term and the product title\n",
    "    \"\"\"\n",
    "    from Levenshtein import distance\n",
    "    train.to_csv('train_with_search_in_attrib.csv')\n",
    "    train = pd.read_csv('train_with_search_in_attrib.csv')\n",
    "    train = train.drop(['Unnamed: 0'], axis = 1)\n",
    "    train['product_title_clean'] = train['product_title'].apply(lambda x: list(set(tokenize(x))))\n",
    "    train['search_term'].fillna('', inplace = True)\n",
    "    train['search_term_split'] = train['search_term'].apply(lambda x: x.split(' '))\n",
    "    \n",
    "    p = []\n",
    "    for i in range(0,74067):\n",
    "        q = []\n",
    "        if len(train['search_term_split'][i][0])>0:\n",
    "            for j in range(len(train['search_term_split'][i])):\n",
    "                for k in range(len(train['product_title_clean'][i])):\n",
    "                    \n",
    "                    if train['search_term_split'][i][j] in train['product_title_clean'][i][k]:\n",
    "                        q.append((train['product_title_clean'][i][k],train['product_title_clean'][i][k]))\n",
    "                        continue\n",
    "                    elif train['search_term_split'][i][j][0] == train['product_title_clean'][i][k][0]:\n",
    "                        q.append((train['search_term_split'][i][j], train['product_title_clean'][i][k]))\n",
    "        p.append(q)\n",
    "    \n",
    "    l = []\n",
    "    for i in range(len(p)):\n",
    "        q = []\n",
    "        for j in range(len(p[i])):\n",
    "            q.append(distance(p[i][j][0], p[i][j][1]))\n",
    "        l.append(q)\n",
    "        \n",
    "    m = []\n",
    "    for q in l:\n",
    "        if q == []:\n",
    "            m.append(1000)\n",
    "        else :\n",
    "            m.append(min(q))\n",
    "\n",
    "    train['min_levenstein_dist_title'] = m\n",
    "    \n",
    "    \n",
    "    return train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_brand_lev_dist(train, attributes):\n",
    "    \"\"\"\n",
    "    Filter out the brand from attributes, join it with train data.\n",
    "    Calculate Levenshtein distance between search term and the brand\n",
    "    \"\"\"\n",
    "    from collections import defaultdict\n",
    "    from Levenshtein import distance\n",
    "    attr_brand = attributes[(attributes['name'].str.lower().str.contains('brand')==True) & attributes['value'].notnull()]\n",
    "    attr_brand = attr_brand.drop('name',axis=1)\n",
    "    attr_brand =attr_brand.rename(columns = {'value':'brand'})\n",
    "    attr_brand['product_uid'] = attr_brand['product_uid'].apply(lambda x:int(x))\n",
    "    \n",
    "    d = defaultdict(list)\n",
    "    p =list(attr_brand['product_uid'])\n",
    "    b = list(attr_brand['brand'])\n",
    "    for i in range(len(p)):\n",
    "        if p[i] not in d:\n",
    "            d[p[i]] = tokenize(b[i])\n",
    "        else:\n",
    "            continue\n",
    "    train['brand'] = train['product_uid'].apply(lambda x: d[x])\n",
    "    train['brand'].fillna('',inplace=True)\n",
    "    train['search_term'].fillna('', inplace = True)\n",
    "    train['search_term_split'] =  train['search_term'].apply(lambda x: x.split(' '))\n",
    "    \n",
    "    p = []\n",
    "    for i in range(74067):\n",
    "        q = []\n",
    "        if len(train['search_term_split'][i][0])>0:\n",
    "            for j in range(len(train['search_term_split'][i])):\n",
    "                for k in range(len(train['brand'][i])):\n",
    "                    if train['search_term_split'][i][j] in train['brand'][i][k]:\n",
    "                        q.append((train['brand'][i][k],train['brand'][i][k]))\n",
    "                        continue\n",
    "                    elif train['search_term_split'][i][j][0] == train['brand'][i][k][0]:\n",
    "                        q.append((train['search_term_split'][i][j], train['brand'][i][k]))\n",
    "        p.append(q)\n",
    "        \n",
    "    l = []\n",
    "    for i in range(len(p)):\n",
    "        q = []\n",
    "        for j in range(len(p[i])):\n",
    "            q.append(distance(p[i][j][0], p[i][j][1]))\n",
    "        l.append(q)\n",
    "        \n",
    "    m = []\n",
    "    for q in l:\n",
    "        if q == []:\n",
    "            m.append(1000)\n",
    "        else :\n",
    "            m.append(min(q))\n",
    "            \n",
    "    train['min_levenstein_dist_brand'] = m\n",
    "    \n",
    "    return train    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine the attributes per product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "attributes = pd.read_csv('attributes.csv', encoding='ISO-8859-1')\n",
    "attrib_per_product = attrib_stack(attributes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Join the attributes with train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv', encoding='ISO-8859-1')\n",
    "train, attrib_per_product = join_attrib(train, attrib_per_product)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look for search term in attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = search_term_in_attrib(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter out the color attribute from attributes data frame and check for presence in the search term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train = color_df(attributes, train)\n",
    "train = search_title_lev_dist(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv('train_with_search_in_attrib.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find levenshtein distance between search term and attribute descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = search_brand_lev_dist(train, attributes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv('train_with_search_in_attrib.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop redundant columns, save only the target variable and features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_temp = train.drop(['id','name','value','search_term_split','color','product_title_clean','brand'] ,axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_temp.to_csv('train_with_distance_metrics.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Invert the Levenshtein distance: Higher the similarity higher the inverted distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_temp['min_levenstein_dist_title'] = train_temp['min_levenstein_dist_title'].apply(lambda x: 10 if x==0 else 1/x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_temp['min_levenstein_dist_brand'] = train_temp['min_levenstein_dist_brand'].apply(lambda x: 10 if x==0 else 1/x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_temp.to_csv('train_with_distance_metrics.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
