{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data and Make PCA, SVM and XGboost model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-06T02:24:31.584192Z",
     "start_time": "2018-12-06T02:24:30.839712Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-06T02:24:32.602911Z",
     "start_time": "2018-12-06T02:24:32.600673Z"
    }
   },
   "outputs": [],
   "source": [
    "# !gzip -d final_combined.csv.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-06T02:25:34.523061Z",
     "start_time": "2018-12-06T02:25:31.060348Z"
    }
   },
   "outputs": [],
   "source": [
    "# load only column names for the data.\n",
    "all_features = pd.read_csv(\"/Users/robertsandor/Documents/MSDS_Classes/MSDS621_Machine_Learning/KaggleHomeDepot/final_combined.csv\", encoding='ISO-8859-1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write out function for getting different subset of features.  \n",
    "### Total three groups, all_similarity_features, all_count_features, len_entropy_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-06T02:25:42.962878Z",
     "start_time": "2018-12-06T02:25:42.959173Z"
    }
   },
   "outputs": [],
   "source": [
    "def getAllNumericalCols(all_features):\n",
    "    \"\"\"\n",
    "    param: all_features is a data frame containning all features.\n",
    "    output: column names of all numerical features.\n",
    "    \"\"\"\n",
    "    col_names = all_features.columns.tolist()\n",
    "    all_num_ind = [15]+list(range(25,len(col_names)))\n",
    "    all_num_col = [col_names[i] for i in all_num_ind]\n",
    "    \n",
    "    return all_num_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-06T02:25:44.058837Z",
     "start_time": "2018-12-06T02:25:44.003291Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>min_levenstein_dist_brand</th>\n",
       "      <th>clean_length</th>\n",
       "      <th>title_length</th>\n",
       "      <th>desc_length</th>\n",
       "      <th>clean_terms_in_title</th>\n",
       "      <th>clean_terms_in_desc</th>\n",
       "      <th>stemmed_terms_in_title</th>\n",
       "      <th>stemmed_terms_in_desc</th>\n",
       "      <th>lemmatized_terms_in_title</th>\n",
       "      <th>lemmatized_terms_in_desc</th>\n",
       "      <th>...</th>\n",
       "      <th>jscore_query_desc</th>\n",
       "      <th>jscore_query_title</th>\n",
       "      <th>search_title_SW</th>\n",
       "      <th>search_desc_SW</th>\n",
       "      <th>NCD_query_title</th>\n",
       "      <th>num_words_in_description</th>\n",
       "      <th>num_stop_words</th>\n",
       "      <th>num_search_words</th>\n",
       "      <th>tfidf_search_common</th>\n",
       "      <th>num_attrib</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.833333</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.107077</td>\n",
       "      <td>79</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.107077</td>\n",
       "      <td>79</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.711111</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.109091</td>\n",
       "      <td>109</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   min_levenstein_dist_brand  clean_length  title_length  desc_length  \\\n",
       "0                       1000           2.0           4.0        129.0   \n",
       "1                       1000           1.0           4.0        129.0   \n",
       "2                          0           1.0          11.0        168.0   \n",
       "\n",
       "   clean_terms_in_title  clean_terms_in_desc  stemmed_terms_in_title  \\\n",
       "0                   1.0                  0.0                     1.0   \n",
       "1                   0.0                  0.0                     0.0   \n",
       "2                   0.0                  0.0                     0.0   \n",
       "\n",
       "   stemmed_terms_in_desc  lemmatized_terms_in_title  lemmatized_terms_in_desc  \\\n",
       "0                    1.0                        1.0                       1.0   \n",
       "1                    0.0                        0.0                       0.0   \n",
       "2                    1.0                        0.0                       1.0   \n",
       "\n",
       "      ...      jscore_query_desc  jscore_query_title  search_title_SW  \\\n",
       "0     ...               2.833333            0.866667              1.0   \n",
       "1     ...               0.000000            0.000000              0.0   \n",
       "2     ...               2.711111            0.000000              0.0   \n",
       "\n",
       "   search_desc_SW  NCD_query_title  num_words_in_description  num_stop_words  \\\n",
       "0             4.0         0.107077                        79               0   \n",
       "1             0.0         0.107077                        79               0   \n",
       "2             3.0         0.109091                       109               1   \n",
       "\n",
       "   num_search_words  tfidf_search_common  num_attrib  \n",
       "0                 2                    1        15.0  \n",
       "1                 2                    0        15.0  \n",
       "2                 2                    1        35.0  \n",
       "\n",
       "[3 rows x 28 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_num_features = all_features[getAllNumericalCols(all_features)]\n",
    "all_num_features.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-06T02:25:56.590336Z",
     "start_time": "2018-12-06T02:25:56.586519Z"
    }
   },
   "outputs": [],
   "source": [
    "def getSimilarityCols(all_num_features):\n",
    "    \"\"\"\n",
    "    param: all_features is a data frame containning all numerical features.\n",
    "    output: column names of all similarity features.\n",
    "    \"\"\"\n",
    "    all_similarity_features = [all_num_features.columns.tolist()[i] for i in [0,14,15,16,17,18,19,20,21,22,26]]\n",
    "    return all_similarity_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-06T02:26:03.446092Z",
     "start_time": "2018-12-06T02:26:03.427776Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>min_levenstein_dist_brand</th>\n",
       "      <th>jaccard_index_title</th>\n",
       "      <th>jaccard_index_desc</th>\n",
       "      <th>lcs_title</th>\n",
       "      <th>lcs_desc</th>\n",
       "      <th>jscore_query_desc</th>\n",
       "      <th>jscore_query_title</th>\n",
       "      <th>search_title_SW</th>\n",
       "      <th>search_desc_SW</th>\n",
       "      <th>NCD_query_title</th>\n",
       "      <th>tfidf_search_common</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>13</td>\n",
       "      <td>2.833333</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.107077</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.107077</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.012048</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2.711111</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.109091</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   min_levenstein_dist_brand  jaccard_index_title  jaccard_index_desc  \\\n",
       "0                       1000             0.166667            0.000000   \n",
       "1                       1000             0.000000            0.000000   \n",
       "2                          0             0.000000            0.012048   \n",
       "\n",
       "   lcs_title  lcs_desc  jscore_query_desc  jscore_query_title  \\\n",
       "0          6        13           2.833333            0.866667   \n",
       "1          3         7           0.000000            0.000000   \n",
       "2          4         4           2.711111            0.000000   \n",
       "\n",
       "   search_title_SW  search_desc_SW  NCD_query_title  tfidf_search_common  \n",
       "0              1.0             4.0         0.107077                    1  \n",
       "1              0.0             0.0         0.107077                    0  \n",
       "2              0.0             3.0         0.109091                    1  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_similarity_features = all_features[getSimilarityCols(all_num_features)]\n",
    "all_similarity_features.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-06T02:26:17.114264Z",
     "start_time": "2018-12-06T02:26:17.110496Z"
    }
   },
   "outputs": [],
   "source": [
    "def getCountAndOtherCols(all_similarity_features,all_num_features):\n",
    "    \"\"\"\n",
    "    return the column names of all count features and len_Entropy columns.\n",
    "    \"\"\"\n",
    "    all_other_num_cols = set(all_num_features.columns.tolist()).difference(set(all_similarity_features.columns.tolist()))\n",
    "    col_has_in = [i for i in all_other_num_cols if \"in\" in i]\n",
    "    len_H_features = list(set(all_other_num_cols).difference(set(col_has_in)))\n",
    "    \n",
    "    return col_has_in, len_H_features\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-06T02:26:28.547293Z",
     "start_time": "2018-12-06T02:26:28.534762Z"
    }
   },
   "outputs": [],
   "source": [
    "count_cols, len_h_cols = getCountAndOtherCols(all_similarity_features,all_num_features)\n",
    "all_count_features = all_features[count_cols]\n",
    "len_entropy_features = all_features[len_h_cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the AWS working on my NCD for query and desc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-06T02:26:50.560647Z",
     "start_time": "2018-12-06T02:26:50.554267Z"
    }
   },
   "outputs": [],
   "source": [
    "\"search_term\" in all_features.columns.tolist()\n",
    "\"product_description\" in all_features.columns.tolist() \n",
    "raw_df = pd.DataFrame(all_features[[\"search_term\",\"product_description\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plan on the modelling plan."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start from simple features and estimated on each model, like SVM.LinearSVR or LinearRegression.  \n",
    "Include only numerical attributes, exclude 0-4.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-06T02:27:17.145672Z",
     "start_time": "2018-12-06T02:27:17.142803Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVR\n",
    "# import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import math\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import linear_model\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-06T02:27:20.178526Z",
     "start_time": "2018-12-06T02:27:20.175488Z"
    }
   },
   "outputs": [],
   "source": [
    "label = all_features[\"relevance\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-06T02:27:23.073961Z",
     "start_time": "2018-12-06T02:27:23.037552Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(all_num_features, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-06T02:27:27.291136Z",
     "start_time": "2018-12-06T02:27:27.246187Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train = np.nan_to_num(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-06T02:28:02.054435Z",
     "start_time": "2018-12-06T02:28:02.050786Z"
    }
   },
   "outputs": [],
   "source": [
    "def standaridize(df):\n",
    "    \"\"\"\n",
    "    Given a vector or a matrix, use the standardize to modify the data. Useful in SVM, L1/L2 regulared linear regression.\n",
    "    return: standaridized data set.\n",
    "    \"\"\"\n",
    "    if len(np.array(df).shape) == 1:\n",
    "        df = np.array(df).reshape(-1,1)\n",
    "    scaler = StandardScaler()\n",
    "    std_df = scaler.fit_transform(df)\n",
    "    return std_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-06T02:28:02.818066Z",
     "start_time": "2018-12-06T02:28:02.808116Z"
    }
   },
   "outputs": [],
   "source": [
    "def runLinearModels(df,label):\n",
    "    \"\"\"\n",
    "    param: pandas data frame with numerical columns.\n",
    "    return: the best model.\n",
    "    \"\"\"\n",
    "    df = standaridize(df)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(df, label)\n",
    "    # Add a quick fix for nan, inf. \n",
    "    X_train = np.nan_to_num(X_train)\n",
    "    X_test = np.nan_to_num(X_test)\n",
    "    \n",
    "    #For linear regression.\n",
    "    lr = linear_model.LinearRegression()\n",
    "    lr_params = {\"fit_intercept\":[True,False],'normalize':[True,False],\"n_jobs\":[-1]}\n",
    "    lr_gs = GridSearchCV(lr,n_jobs=-1,cv=5,param_grid=lr_params)\n",
    "    lr_gs.fit(X_train,y_train)\n",
    "    lr_predicted = lr_gs.predict(X_test)\n",
    "    lr_rmse = math.sqrt(mean_squared_error(lr_predicted, y_test))\n",
    "\n",
    "    #For Lasso, the key parameter to tune on is alpha, and it is numerical within range of 0 and 1.\n",
    "    lsso = linear_model.Lasso(random_state=42,tol=0.001)\n",
    "    lsso_params = {\"fit_intercept\":[True,False],'normalize':[True,False],\"alpha\":list(np.linspace(0.1,1.5,num=20))}\n",
    "    lsso_gs = GridSearchCV(lsso,n_jobs=-1,cv=5,param_grid=lsso_params)\n",
    "    lsso_gs.fit(X_train,y_train)\n",
    "    lsso_predicted = lsso_gs.predict(X_test)\n",
    "    lsso_rmse = math.sqrt(mean_squared_error(lsso_predicted, y_test))\n",
    "\n",
    "    #For Ridge, the key parameter is alpha.\n",
    "    ridge = linear_model.Ridge(random_state=42,tol=0.001)\n",
    "    ridge_params = {\"fit_intercept\":[True,False],'normalize':[True,False],\"alpha\":list(np.linspace(0.1,4,num=40))}\n",
    "    ridge_gs = GridSearchCV(ridge,n_jobs=-1,cv=5,param_grid=ridge_params)\n",
    "    ridge_gs.fit(X_train,y_train)\n",
    "    ridge_predicted = ridge_gs.predict(X_test)\n",
    "    ridge_rmse = math.sqrt(mean_squared_error(ridge_predicted, y_test))\n",
    "\n",
    "    #For Elastic nets, the key parameter is alpha and l1_ratio, both of them are numerical.\n",
    "    elNet = linear_model.ElasticNet(random_state=42,tol=0.001)\n",
    "    elNet_params = {\"fit_intercept\":[True,False],'normalize':[True,False],\"alpha\":list(np.linspace(0.1,1,num=20)),\"l1_ratio\":list(np.linspace(0,1,num=10))}\n",
    "    elNet_gs = GridSearchCV(elNet,n_jobs=-1,cv=5,param_grid=elNet_params)\n",
    "    elNet_gs.fit(X_train,y_train)\n",
    "    elNet_predicted = elNet_gs.predict(X_test)\n",
    "    elNet_rmse = math.sqrt(mean_squared_error(elNet_predicted, y_test))\n",
    "    \n",
    "    all_rmse = [lr_rmse, lsso_rmse, ridge_rmse, elNet_rmse] \n",
    "    model_names = [lr_gs, lsso_gs, ridge_gs, elNet_gs]\n",
    "    best_model = dict(zip(model_names, all_rmse))\n",
    "\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-06T02:28:04.408457Z",
     "start_time": "2018-12-06T02:28:04.371333Z"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-91e3adbb9321>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Use smallest data set to train. Best performance is LinearRegression.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# This runs 2m 38s.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mlinear_family\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrunLinearModels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen_entropy_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-21-f99607722ad5>\u001b[0m in \u001b[0;36mrunLinearModels\u001b[0;34m(df, label)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mbest\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \"\"\"\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstandaridize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-20-a81b38bf5595>\u001b[0m in \u001b[0;36mstandaridize\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mscaler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mstd_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mstd_df\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    515\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m             \u001b[0;31m# fit method of arity 1 (unsupervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    518\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/data.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    588\u001b[0m         \u001b[0;31m# Reset internal state before fitting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    589\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 590\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartial_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    591\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpartial_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/data.py\u001b[0m in \u001b[0;36mpartial_fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    610\u001b[0m         \"\"\"\n\u001b[1;32m    611\u001b[0m         X = check_array(X, accept_sparse=('csr', 'csc'), copy=self.copy,\n\u001b[0;32m--> 612\u001b[0;31m                         warn_on_dtype=True, estimator=self, dtype=FLOAT_DTYPES)\n\u001b[0m\u001b[1;32m    613\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m         \u001b[0;31m# Even in the case of `with_mean=False`, we update the mean anyway\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    451\u001b[0m                              % (array.ndim, estimator_name))\n\u001b[1;32m    452\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 453\u001b[0;31m             \u001b[0m_assert_all_finite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    454\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m     \u001b[0mshape_repr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_shape_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X)\u001b[0m\n\u001b[1;32m     42\u001b[0m             and not np.isfinite(X).all()):\n\u001b[1;32m     43\u001b[0m         raise ValueError(\"Input contains NaN, infinity\"\n\u001b[0;32m---> 44\u001b[0;31m                          \" or a value too large for %r.\" % X.dtype)\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "# Use smallest data set to train. Best performance is LinearRegression.\n",
    "# This runs 2m 38s. \n",
    "linear_family = runLinearModels(len_entropy_features,label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-05T06:53:32.222713Z",
     "start_time": "2018-12-05T06:53:32.220032Z"
    }
   },
   "outputs": [],
   "source": [
    "rmse_linear_fam1 = [i[1] for i in a]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-05T06:58:43.304513Z",
     "start_time": "2018-12-05T06:53:32.224658Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jw/miniconda3/lib/python3.6/site-packages/sklearn/preprocessing/data.py:617: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/Users/jw/miniconda3/lib/python3.6/site-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/Users/jw/miniconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "# get all linear family regression.\n",
    "\n",
    "linear_family2 = runLinearModels(all_count_features,label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-05T07:05:07.407521Z",
     "start_time": "2018-12-05T06:58:43.306258Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jw/miniconda3/lib/python3.6/site-packages/sklearn/preprocessing/data.py:617: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/Users/jw/miniconda3/lib/python3.6/site-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/Users/jw/miniconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "linear_family3 = runLinearModels(all_similarity_features,label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-05T15:30:16.890336Z",
     "start_time": "2018-12-05T15:13:29.395930Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jw/miniconda3/lib/python3.6/site-packages/sklearn/preprocessing/data.py:617: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/Users/jw/miniconda3/lib/python3.6/site-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/Users/jw/miniconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "linear_family4 = runLinearModels(all_num_features,label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-05T15:30:16.896982Z",
     "start_time": "2018-12-05T15:30:16.893113Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-05T15:30:16.905481Z",
     "start_time": "2018-12-05T15:30:16.899382Z"
    }
   },
   "outputs": [],
   "source": [
    "def runSVMregession(df,label):\n",
    "    \"\"\"\n",
    "    Doing SVM regression on large data set require specify the cache size, scale input X data to [0,1]/[-1,1]\n",
    "        avoid \n",
    "    param: pandas data frame with numerical columns.\n",
    "    return: the best model.\n",
    "    \"\"\"\n",
    "    # Scale the df.\n",
    "    df = standaridize(df)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df, label)\n",
    "    # Add a quick fix for nan, inf. \n",
    "    X_train = np.nan_to_num(X_train)\n",
    "    X_test = np.nan_to_num(X_test)\n",
    "    \n",
    "    svm = LinearSVR(random_state=42,max_iter=5000,C=100,epsilon=0.075)\n",
    "    svm_regression_params = {\"tol\":[10**(-4),10**(-5)],'C':[1,10,20,100,300],\"epsilon\":[0.1,0.2,0.075],\"max_iter\":[4000,5000,10000]}\n",
    "    svm_gs = GridSearchCV(svm,n_jobs=-1,cv=3,param_grid=svm_regression_params)\n",
    "    svm_gs.fit(X_train,y_train)\n",
    "    svm_predicted = svm_gs.predict(X_test)\n",
    "    svm_rmse = math.sqrt(mean_squared_error(svm_predicted,y_test))\n",
    "    \n",
    "    return [svm_gs,svm_rmse]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-12-05T15:13:34.811Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jw/miniconda3/lib/python3.6/site-packages/sklearn/preprocessing/data.py:617: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/Users/jw/miniconda3/lib/python3.6/site-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    }
   ],
   "source": [
    "svm_ls = runSVMregession(len_entropy_features,label)\n",
    "svm_ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-12-05T15:13:35.491Z"
    }
   },
   "outputs": [],
   "source": [
    "svm_ls2 = runSVMregession(all_count_features,label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-12-05T15:13:35.883Z"
    }
   },
   "outputs": [],
   "source": [
    "svm_ls2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-12-05T15:13:36.491Z"
    }
   },
   "outputs": [],
   "source": [
    "svm_ls3 = runSVMregession(all_similarity_features,label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-12-05T15:13:37.349Z"
    }
   },
   "outputs": [],
   "source": [
    "svm_ls3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-12-05T15:13:39.166Z"
    }
   },
   "outputs": [],
   "source": [
    "svm_ls4 = runSVMregession(all_num_features,label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-12-05T15:13:39.873Z"
    }
   },
   "outputs": [],
   "source": [
    "svm_ls4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-05T07:05:07.428483Z",
     "start_time": "2018-12-05T06:50:04.823Z"
    }
   },
   "outputs": [],
   "source": [
    "# collect all svm performance.\n",
    "rmse_svm = [i[1] for i in [svm_ls,svm_ls2,svm_ls3,svm_ls4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-05T06:23:19.079199Z",
     "start_time": "2018-12-05T06:23:19.075510Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5562035877884243,\n",
       " 0.5254573621899448,\n",
       " 0.5076691880561738,\n",
       " 0.5418303047801409]"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse_svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-05T03:27:17.755394Z",
     "start_time": "2018-12-05T03:27:17.752277Z"
    }
   },
   "outputs": [],
   "source": [
    "def runXGBoost(df):\n",
    "    \"\"\"\n",
    "    ref: https://xgboost.readthedocs.io/en/latest/python/python_intro.html\n",
    "    param: pandas data frame with numerical columns.\n",
    "    return: the best model.\n",
    "    \"\"\"\n",
    "    \n",
    "    # specify parameters via map, definition are same as c++ version\n",
    "    param = {'max_depth':2, 'eta':1, 'silent':1, 'objective':'binary:logistic'}\n",
    "\n",
    "    # specify validations set to watch performance\n",
    "    watchlist = [(dtest, 'eval'), (dtrain, 'train')]\n",
    "    num_round = 2\n",
    "    bst = xgb.train(param, dtrain, num_round, watchlist)\n",
    "\n",
    "    # this is prediction\n",
    "    preds = bst.predict(dtest)\n",
    "    labels = dtest.get_label()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Doing visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-05T06:30:30.706710Z",
     "start_time": "2018-12-05T06:30:30.541999Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-05T06:48:18.554106Z",
     "start_time": "2018-12-05T06:47:28.496Z"
    }
   },
   "outputs": [],
   "source": [
    "#plot line graph for each features space.\n",
    "\n",
    "features_ls = [\"length&Entropy\",\"Counts features\",\"Similarity scores\",\"All Numerical Features!\"]\n",
    "color_ls = ['green','blue','yellow','orange','red']\n",
    "model_ls = [\"Linear Regression\",\"Lasso\",\"Ridge\",\"Elastic Net\",\"SVM regression\"]\n",
    "rmse_ls = [rmse_lr,rmse_lasso,rmse_ridge,rmse_elNet,rmse_svm]\n",
    "\n",
    "#for i in range(len(model_ls)):\n",
    "#    plt.plot(features_ls,rmse_ls[i], color=color_ls[i])\n",
    "\n",
    "plt.plot(features_ls,rmse_svm, color=color_ls[4])\n",
    "plt.xlabel('Feature Spaces')\n",
    "plt.ylabel('Model Name')\n",
    "plt.title('Line graph of RMSE on Various Feature Spaces')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
