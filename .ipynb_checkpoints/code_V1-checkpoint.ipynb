{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.feature_extraction import stop_words\n",
    "\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from scipy import spatial\n",
    "import operator\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_file = 'glove.6B.300d.txt'\n",
    "def make_dictionary(file):\n",
    "    '''\n",
    "    Initiate the glove model as a dictionary\n",
    "    input: A String which is a file in the project directory\n",
    "    returns: A dictionary with item = word : 300 d list\n",
    "    '''\n",
    "    vecs = dict()\n",
    "    with open(file) as f:\n",
    "        lines = f.readlines()\n",
    "        for word_and_vec in lines:\n",
    "            elems = word_and_vec.strip().split(' ')\n",
    "            word = elems[0]\n",
    "            vec = np.array(elems[1:], dtype=float)\n",
    "            vecs[word] = vec\n",
    "    return vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_dic = make_dictionary(glove_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "stops = list(stop_words.ENGLISH_STOP_WORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "products = pd.read_csv('product_descriptions.csv')\n",
    "train = pd.read_csv('train.csv', encoding='ISO-8859-1')\n",
    "train = train.set_index('product_uid').join(products.set_index('product_uid'))\n",
    "train = train.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_term=train['search_term']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_term_list(search_terms:list):\n",
    "    f = open('output.txt', \"w\")\n",
    "    f.close()\n",
    "    for i in range(len(search_terms)):\n",
    "        t=''\n",
    "        search_terms[i]=search_terms[i].lower()\n",
    "        for term in search_terms[i].split(' '):\n",
    "            if ( term.isalpha() and len(term)>2 and (term not in stops) and (term in glove_dic)):\n",
    "                t = t +' '+ term\n",
    "        search_terms[i]=t\n",
    "\n",
    "        f = open('output.txt', \"a\")\n",
    "        f.write(search_terms[i])\n",
    "        f.write('\\n')\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the following code takes hours....\n",
    "# you can load the 'output.txt' file to check the result\n",
    "\n",
    "# clean_term_list(search_term)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"output.txt\",\"rt\") \n",
    "clean_terms = f.readlines()\n",
    "clean_terms = [line.strip() for line in clean_terms]\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0         angle bracket\n",
      "1             l bracket\n",
      "2             deck over\n",
      "3      rain shower head\n",
      "4    shower only faucet\n",
      "Name: search_term, dtype: object\n",
      "['angle bracket', 'bracket', 'deck', 'rain shower head', 'shower faucet']\n"
     ]
    }
   ],
   "source": [
    "print(train['search_term'][:5])\n",
    "print(clean_terms[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['clean_terms']=clean_terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned = list(train['clean_terms'])  # without transfering into list, the changes made on cleaned will be made on train!\n",
    "title = list(train['product_title'])\n",
    "desc = list(train['product_description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['angle bracket', 'bracket', 'deck', 'rain shower head', 'shower faucet']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_length=np.zeros(len(cleaned))\n",
    "for i in range(len(cleaned)):\n",
    "        if not pd.isnull(cleaned[i]):\n",
    "            clean_length[i]=len(cleaned[i].split(' '))\n",
    "            \n",
    "train['clean_length']=clean_length  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_length=np.zeros(len(title))\n",
    "for i in range(len(title)):\n",
    "        title_length[i]=len(title[i].split(' '))\n",
    "            \n",
    "train['title_length']=title_length    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "desc_length=np.zeros(len(desc))\n",
    "for i in range(len(desc)):\n",
    "        desc_length[i]=len(desc[i].split(' '))\n",
    "            \n",
    "train['desc_length']=desc_length  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_term_in_doc(terms:list, title:list):\n",
    "    count=np.zeros(len(terms))\n",
    "    for i in range(len(terms)):\n",
    "        if not pd.isnull(terms[i]): \n",
    "            title[i]=title[i].lower()\n",
    "            #print(terms[i])\n",
    "            for term in terms[i].split(' '):\n",
    "                #print(term, title[i].split(' '))\n",
    "                if term in title[i].split(' '):\n",
    "                    count[i]+=1\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_title = clean_term_in_doc(cleaned, title)\n",
    "c_desc = clean_term_in_doc(cleaned, desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['clean_terms_in_title']=c_title\n",
    "train['clean_terms_in_desc']=c_desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_uid</th>\n",
       "      <th>id</th>\n",
       "      <th>product_title</th>\n",
       "      <th>search_term</th>\n",
       "      <th>relevance</th>\n",
       "      <th>product_description</th>\n",
       "      <th>clean_terms</th>\n",
       "      <th>clean_length</th>\n",
       "      <th>title_length</th>\n",
       "      <th>desc_length</th>\n",
       "      <th>clean_terms_in_title</th>\n",
       "      <th>clean_terms_in_desc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100001</td>\n",
       "      <td>2</td>\n",
       "      <td>Simpson Strong-Tie 12-Gauge Angle</td>\n",
       "      <td>angle bracket</td>\n",
       "      <td>3.00</td>\n",
       "      <td>Not only do angles make joints stronger, they ...</td>\n",
       "      <td>angle bracket</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100001</td>\n",
       "      <td>3</td>\n",
       "      <td>Simpson Strong-Tie 12-Gauge Angle</td>\n",
       "      <td>l bracket</td>\n",
       "      <td>2.50</td>\n",
       "      <td>Not only do angles make joints stronger, they ...</td>\n",
       "      <td>bracket</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100002</td>\n",
       "      <td>9</td>\n",
       "      <td>BEHR Premium Textured DeckOver 1-gal. #SC-141 ...</td>\n",
       "      <td>deck over</td>\n",
       "      <td>3.00</td>\n",
       "      <td>BEHR Premium Textured DECKOVER is an innovativ...</td>\n",
       "      <td>deck</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100005</td>\n",
       "      <td>16</td>\n",
       "      <td>Delta Vero 1-Handle Shower Only Faucet Trim Ki...</td>\n",
       "      <td>rain shower head</td>\n",
       "      <td>2.33</td>\n",
       "      <td>Update your bathroom with the Delta Vero Singl...</td>\n",
       "      <td>rain shower head</td>\n",
       "      <td>3.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100005</td>\n",
       "      <td>17</td>\n",
       "      <td>Delta Vero 1-Handle Shower Only Faucet Trim Ki...</td>\n",
       "      <td>shower only faucet</td>\n",
       "      <td>2.67</td>\n",
       "      <td>Update your bathroom with the Delta Vero Singl...</td>\n",
       "      <td>shower faucet</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   product_uid  id                                      product_title  \\\n",
       "0       100001   2                  Simpson Strong-Tie 12-Gauge Angle   \n",
       "1       100001   3                  Simpson Strong-Tie 12-Gauge Angle   \n",
       "2       100002   9  BEHR Premium Textured DeckOver 1-gal. #SC-141 ...   \n",
       "3       100005  16  Delta Vero 1-Handle Shower Only Faucet Trim Ki...   \n",
       "4       100005  17  Delta Vero 1-Handle Shower Only Faucet Trim Ki...   \n",
       "\n",
       "          search_term  relevance  \\\n",
       "0       angle bracket       3.00   \n",
       "1           l bracket       2.50   \n",
       "2           deck over       3.00   \n",
       "3    rain shower head       2.33   \n",
       "4  shower only faucet       2.67   \n",
       "\n",
       "                                 product_description       clean_terms  \\\n",
       "0  Not only do angles make joints stronger, they ...     angle bracket   \n",
       "1  Not only do angles make joints stronger, they ...           bracket   \n",
       "2  BEHR Premium Textured DECKOVER is an innovativ...              deck   \n",
       "3  Update your bathroom with the Delta Vero Singl...  rain shower head   \n",
       "4  Update your bathroom with the Delta Vero Singl...     shower faucet   \n",
       "\n",
       "   clean_length  title_length  desc_length  clean_terms_in_title  \\\n",
       "0           2.0           4.0        129.0                   1.0   \n",
       "1           1.0           4.0        129.0                   0.0   \n",
       "2           1.0          11.0        168.0                   0.0   \n",
       "3           3.0          13.0        104.0                   1.0   \n",
       "4           2.0          13.0        104.0                   2.0   \n",
       "\n",
       "   clean_terms_in_desc  \n",
       "0                  0.0  \n",
       "1                  0.0  \n",
       "2                  0.0  \n",
       "3                  1.0  \n",
       "4                  2.0  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Potential Model\n",
    "\n",
    "We preprocessed both the search terms and the title by removing numbers and extraneous stop words from them. We decided to remove the numbers because the relevancy of the results from retrieving the closest words from the Glove dictionary was substantially improved after doing so.\n",
    "\n",
    "We are creating a model based on the number of words in the \"cleaned\" search terms, the number of words in the \"cleaned\" title, the number of words in the \"cleaned\" description length, the count of how many times one of the cleaned search terms appeared in title, and the count of how many times one of the cleaned search terms appeared in the description. We think there might be some relationship between how many times the search terms appeared in the title or description and the relevancy of the search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "import string\n",
    "from nltk.stem.porter import *\n",
    "from sklearn.feature_extraction import stop_words\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from math import sqrt\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    \"\"\"\n",
    "    Tokenize text and return a non-unique list of tokenized words\n",
    "    found in the text. Normalize to lowercase, strip punctuation,\n",
    "    remove stop words, drop words of length < 3, strip digits.\n",
    "    \"\"\"\n",
    "    stops = list(stop_words.ENGLISH_STOP_WORDS)\n",
    "    text = text.lower()\n",
    "    regex = re.compile('[' + re.escape(string.punctuation) + '0-9\\\\r\\\\t\\\\n]')\n",
    "    nopunct = regex.sub(\" \", text)  # delete stuff but leave at least a space to avoid clumping together\n",
    "    words = nopunct.split(\" \")\n",
    "    words = [w for w in words if (len(w) > 2 and (w not in stops))]  # ignore a, an, to, at, be, ...\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_length(column):\n",
    "    \"\"\"\n",
    "    This calculates and returns the number of words\n",
    "    for each row in a specified column\n",
    "    \"\"\"\n",
    "    length = np.zeros(len(column))\n",
    "    for index in range(len(column)):\n",
    "        print(column[index])\n",
    "        if not pd.isnull(column[index]):\n",
    "            length[index] = len(column[index].split(' '))\n",
    "    return length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   clean_length  title_length  desc_length  clean_terms_in_title  \\\n",
      "0           2.0           4.0        129.0                   1.0   \n",
      "1           1.0           4.0        129.0                   0.0   \n",
      "2           1.0          11.0        168.0                   0.0   \n",
      "3           3.0          13.0        104.0                   1.0   \n",
      "4           2.0          13.0        104.0                   2.0   \n",
      "5           2.0          15.0        490.0                   1.0   \n",
      "6           2.0          15.0        490.0                   1.0   \n",
      "7           1.0          15.0        490.0                   0.0   \n",
      "8           2.0           9.0        120.0                   1.0   \n",
      "9           1.0          14.0         82.0                   1.0   \n",
      "\n",
      "   clean_terms_in_desc  \n",
      "0                  0.0  \n",
      "1                  0.0  \n",
      "2                  0.0  \n",
      "3                  1.0  \n",
      "4                  2.0  \n",
      "5                  1.0  \n",
      "6                  1.0  \n",
      "7                  0.0  \n",
      "8                  2.0  \n",
      "9                  1.0  \n",
      "   relevance\n",
      "0       3.00\n",
      "1       2.50\n",
      "2       3.00\n",
      "3       2.33\n",
      "4       2.67\n",
      "5       3.00\n",
      "6       2.67\n",
      "7       3.00\n",
      "8       2.67\n",
      "9       3.00\n"
     ]
    }
   ],
   "source": [
    "#X_train = train[['clean_length', 'title_length', 'desc_length', 'clean_terms_in_title', 'clean_terms_in_desc']]\n",
    "X_train = train[['clean_terms_in_title', 'clean_terms_in_desc']]\n",
    "y_train = train[['relevance']]\n",
    "print(X_train[:10])\n",
    "print(y_train[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# since we can't see the relevancy scores of the test set,\n",
    "# I decided to split the training set \n",
    "train_data, test_data, train_target, test_target = train_test_split(X_train,\n",
    "                                                                        y_train,\n",
    "                                                                        random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_reg_model = LinearRegression()\n",
    "lin_reg_model.fit(train_data, train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.12839404],\n",
       "       [2.34648638],\n",
       "       [2.40951281],\n",
       "       [2.64887041],\n",
       "       [2.63710402]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted = lin_reg_model.predict(test_data)\n",
    "print(predicted[:5])\n",
    "print(test_target[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5162702750709969"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# since I couldn't find an RMSE function in the sklearn library,\n",
    "# I just used the MSE function and took the square root of that\n",
    "rmse_lin_reg = sqrt(mean_squared_error(predicted, test_target))\n",
    "rmse_lin_reg\n",
    "# this value is equivalent to rank 1756 on the Kaggle leaderboard for this competition\n",
    "# the benchmark was ~ rank 1680 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('test.csv', encoding='ISO-8859-1')\n",
    "test[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.set_index('product_uid').join(products.set_index('product_uid'))\n",
    "test = test.reset_index()\n",
    "test[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here I take the search_term column...\n",
    "search_term_test = test['search_term']\n",
    "search_term_test[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is basically the equivalent of the clean_term_list function created above\n",
    "# this effectively removes any stop words and numbers in the search terms\n",
    "cleaned_search_term_test = [' '.join(tokenize(search_term)) for search_term in search_term_test]\n",
    "cleaned_search_term_test[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['clean_terms'] = cleaned_search_term_test\n",
    "\n",
    "cleaned_test = list(test['clean_terms'])\n",
    "title_test = list(test['product_title'])\n",
    "desc_test = list(test['product_description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cleaned_test[:5])\n",
    "print(title_test[:5])\n",
    "print(desc_test[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['clean_length'] = get_length(cleaned_test)\n",
    "test['clean_length'][0]\n",
    "test['title_length'] = get_length(title_test)\n",
    "test['title_length'][0]\n",
    "test['desc_length'] = get_length(desc_test)\n",
    "test['desc_length'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['clean_terms_in_title'] = clean_term_in_doc(cleaned_test, title_test)\n",
    "test['clean_terms_in_desc'] = clean_term_in_doc(cleaned_test, desc_test)\n",
    "test[:5]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
